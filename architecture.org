* The Elements of Computing Systems
:PROPERTIES:
:Title: The Elements of Computing Systems
:Author: Noam Nisan, Shimon Schocken
:CATEGORY: nand2tetris
:END:
** Introduction
This book teaches three things:

1. How computers work
2. How to break complex problems into manageable modules
3. How to develop large-scale hardware and software systems

We will be learning how to create a complete and working computer system, from the ground-up.

"/The only kind of learning which significantly influences behavior is self-discovered or self-appropriated--truth that has been assimilated in experience./"
*** The World Above
Consider this trivial code:

#+BEGIN_SRC C
int main (void) {
  printf("%s", "Hello world!");
  return 0;
}
#+END_SRC

This is written in C. Newcomers often see the =void= or =%s= and ask what they mean, because they tend to be a bit too low level to understand at first glance.

What if I told you this wasn't even scratching the surface? For the computer to understand C, it must /parse/ the text, /uncover/ the semantics, and /reexpress it/ into something that can be understood by a computer. This step is known as *compilation*. C compiles down to assembly code, which compiles down to machine code.

Also, consider that /machine language itself is also an abstraction/. It is a set of binary codes that was designed to work specifically with the machine that is running the code. That is, it must be realized with a certain /chipset/ that is built using a specific system architecture. These chipset devices contain registers, memory units, ALU, and so on.

Going even deeper, realize that each of these devices is functionally held together by /logic gates/: Specific combinations of transistors that deterministically produce the same logical output if given the same logical input.

The nuances of any computer program, starting from the first transistor and leading up to the UX, start from the very bottom--the first transistor.

An intimate understanding of the world below is one of the things that separates naive programmers from sophisticated developers--people who can create complex /technologies/, not just /applications/ (of technologies that already exist).
*** Abstractions
It is through building abstractions from the bottom up that we free up the mental capacity to actually go so far up.

We built the NAND gate, and we abstracted it away from our thoughts so that we could focus on other thing. This led to AND, which leads to OR, which leads to XOR, which leads to the adder... and so on. A good abstraction focuses only on "What is this thing doing?" rather than "How does it do it?".
*** The World Below
<<1-world-below>>
As we dive into the lands below, we'll find out more about the following...
**** High-Level Language Land
**** The Road Down to Hardware Land
**** Hardware Land
** Chapter 1: Boolean Logic
Every digital device is based on a set of chips designed to store and process information. They share the same common hardware: *Boolean logic gates*.
*** 1.1 - Background
This chapter focuses on the construction of logic gates. To do this, we'll need to know some Boolean algebra!
**** 1.1.1 - Boolean Algebra
There are two rules in Boolean algebra: Yes and no, /1 and 0/.
***** Truth tables
The most common and simplest way to specify a Boolean function is to write a truth table, which graphically represents a given Boolean function's output for given input. They can also be represented as mathematical functions. See [[fig-1.1][Figure 1.1]].

+--------+--------+--------+--------+
|x       |y       |z       |f(x,y,z)|
+--------+--------+--------+--------+
|0       |0       |0       |0       |
+--------+--------+--------+--------+
|0       |0       |1       |0       |
+--------+--------+--------+--------+
|0       |1       |0       |1       |
+--------+--------+--------+--------+
|0       |0       |1       |0       |
+--------+--------+--------+--------+
|1       |0       |0       |1       |
+--------+--------+--------+--------+
|1       |0       |1       |0       |
+--------+--------+--------+--------+
|1       |1       |0       |1       |
+--------+--------+--------+--------+
|1       |1       |1       |0       |
+--------+--------+--------+--------+
/Figure 1.1: Truth table representation of a Boolean function =f(x, y, z) = (x + y) * z'=. <<fig-1.1>>/
***** Canonical representation
Also called /minterm/ and /maxterm/:

- The /minterm/ is gathered by taking a truth table and Adding together literals whose combinations produce a function output of =1=,then Or-ing those terms together.
- The /maxterm/ is gathered by taking a truth table and doing the same thing, but in reverse order.

Doing either of these results in an expression that is equivalent to the logic expressed by the entire truth table. Using the canonical representation is a way to formulate a simple expression.

This also teaches us that *all Boolean functions can be built with =And=, =Or=, and =Not=.*
**** 1.1.2 - Gate Logic
A /gate/ is a physical device that implements a Boolean function. Physically, a gate works by connecting I/O to I/O pins. The structure of the gate determines what the input/output of each pin should be to achieve a particular result. Gates are implemented today using /transistors/.

We begin our process of abstraction with gates.
***** Primitive and composite gates
A /composite gate/ is simply an implementation of a (usually more complex than normal) logical function through the use of two or more gates. For example, the three-input =And= is implemented by =And(And(a, b), c)=.

A gate /interface/ refers to dealing mainly with the gate's I/O, while gate /implementation/ deals with actually putting the circuit together using primitive gates. The only reason computer programmers really deal with gate implementation is to try to optimize low-level logic past what is currently possible in a given system. Meaning, the only requirement a computer programmer needs out of working with gates is the guarantee that all gates of the same type will produce the same results, with the same interface.
**** 1.1.3 - Actual hardware construction
While it is easy to chain together primitive gates to arrive at simpler composite gate designs, testing the logical function of these gates quickly becomes physically unviable if we were to be building these gates ourselves. This is why we use virtual tools like /HDL (Hardware Description Language)/ and /VHDL (Virtual HDL)/.
**** 1.1.4 - Hardware Description Language (HDL) <<1-hdl>>
<2019-01-15 Tue 11:50>
HDL/VHDL is a fancy way to imply that "we test our circuits in a simulation environment". HDL is the standard by which many gates are tested before fabrication, and is the first language abstraction we have run into so far.
***** Guts of a HDL program
There are a few parts to an HDL program:
****** Header
The /header/ section specifies the chip /interface/ (=CHIP=). It specifies the chip name and the names of all input and output pins.
****** Parts
The /parts/ (=PARTS=) section describes the names and topology of all the lower-level parts (other chips) from which this particular chip is constructed. Each part is represented by a /statement/ that specifies this part name, and crucially, the way it is connected to the other parts of the design.

Inter-part connections are described by creating and connecting /internal pins/ as needed. All =PARTS= connections are passed into gate interfaces as needed. See [[1-fig-1.6a][Figure 1.6a]] for an implementation of HDL to construct a XOR gate.

#+BEGIN_SRC
/* Xor.hdl */
CHIP Xor {
  IN a, b; /* these are external */
  OUT out; /* same */
  PARTS:
    Not(in=a, out=nota); /* using a new internal pin `nota` */
    Not(in=b, out=notb); /* the fact that `Not` has input pin `in` is an API specification */
    And(a=a, b=notb, out=w1);
    And(a=nota, b=b, out=w2);
    Or(a=w1, b=w2, out=out);
}
#+END_SRC
/Figure 1.6a: A =Xor= gate implemented in HDL./ <<1-fig-1.6a>>
****** Testing
HDL scripts are contained within file extension =.hdl=, while tests are contained within =.tst=. A test script simply assigns binary inputs to the chip interface and produces the logical output file to a =.out= file, as a truth table. The syntax is as follows ([[1-fig-1.6b][Figure 1.6b]]).

#+BEGIN_SRC
load Xor.hdl,
output-list a, b, out;
set a 0, set b 0;
eval, output;
set a 0, set b 1;
eval, output;
set a 1, set b 0;
eval, output;
set a 1, set b 1;
#+END_SRC
/Figure 1.6b: A =Xor= gate test, =Xor.tst=./ <<1-fig-1.6b>>
**** 1.1.5 -  Hardware Simulation
Since HDL is a hardware construction /language/, the process of writing and debugging HDL programs is pretty much the same as in software development. If we were using a compiled language like C, we would send our raw code to a compiler to be translated into assembly. Instead, however, we use a /hardware simulator/.

A hardware simulator is also a computer program... it's really just a HDL compiler, but the purpose of HDL is very specific, hence the name of the compiler.
*** 1.2 - Specification
Now we will specify a typical set of gates, each designed to carry out a common Boolean operation. We will be following these gates all the way to the design of a modern computer!
**** 1.2.1 - Nand
The truth table specification is as follows:
+-----+-----+----------+
|a    |b    |Nand(a, b)|
+-----+-----+----------+
|0    |0    |1         |
|0    |1    |1         |
|1    |0    |1         |
|1    |1    |0         |
+-----+-----+----------+

The API specification is as follows:
#+BEGIN_SRC
Chip name: Nand
Inputs:    a, b
Outputs:   out
Function:  If a=b=1 then out=0 else out=1
Comment:   This gate is considered primitive and thus there is no need to implement it.
#+END_SRC
**** 1.2.2 - Basic Logic Gates
Here is the API specification for other basic logic gates.
***** Not
#+BEGIN_SRC
Chip name: Not
Inputs:    in
Outputs:   out
Function:  If in=0 then out=1 else out=0
#+END_SRC
***** And
#+BEGIN_SRC
Chip name: And
Inputs:    a, b
Outputs:   out
Function:  If a=b=1 then out=1 else out=0
#+END_SRC
***** Or
#+BEGIN_SRC
Chip name: Or
Inputs:    a, b
Outputs:   out
Function:  If a=1 or b=1 then out=1 else out=0
#+END_SRC
***** Multiplexor
#+BEGIN_SRC
Chip name: Mux
Inputs:    a, b, sel
Outputs:   out
Function:  If sel=0 then out=a else out=b
#+END_SRC

A multiplexor is a three-input gate that uses one of the inputs as a /selection bit/, and picks either =a= or =b= as its output depending on that selection bit. (=a= and =b= are usually the result of other input functions!)
***** Demultiplexor
#+BEGIN_SRC
Chip name: DMux
Inputs:    in, sel
Outputs:   a, b
Function:  If sel=0 then {a=in, b=0} else {a=0, b=in}
#+END_SRC
A demultiplexor is similar in that it takes in a single input plus a selection bit, then produces two outputs. One of the outputs (=a= or =b=) is then assigned the value of =in= depending on the value of =sel=.
**** 1.2.3 - Multi-Bit Versions of Basic Gates
Today, computer hardware is typically designed to operate on multi-bit arrays, not just single bits. These are called /buses/. A 32-bit bus, for example, simply operates on 32 bits at once, taking in 32 inputs from an input bus, and outputting another 32 bits. The buses do not incorporate multiple gates /in series/, but rather /in parallel/, so that outputs are all individual.
**** 1.2.4 - Multi-Way Versions of Basic Gates
An /n-way/ gate, on the other hand, /does/ wire primitive gates in series. An /8-way =Or= gate/, for example, has eight input pins, =in[8]=, and produces a single output if any of those input pints are set to =1=.
***** The M-Way/N-Bit Multiplexor
Multiplexors used multi-bit multi-way are essential in constructing computer platforms. Let's break it down:

A *16-bit multiplexor* consists of an input =in[16]= plus selection bit =sel=, and an output =out[16]=:
#+BEGIN_SRC
Chip name: Mux4
Inputs:    in[16], sel
Outputs:   out[16]
Function:  If sel=0 then for i=0...15 out[i]=a[i] ... else out[i]=b[i]
#+END_SRC

A *4-way multiplexor* consists of an input =in[4]= plus two selection bits, corresponding to the number of possible input permutations, and a single output:
#+BEGIN_SRC
Chip name: Mux4Way
Inputs:    in[4], sel0, sel1
Outputs:   out
Function:  If Nand(sel0, sel1) then out=in[0], if sel0, Not(sel1) then out=in[1] ... etc.
#+END_SRC

A *16-bit, 4-way multiplexor* consists of four 16-bit inputs =a[16], b[16], c[16], d[16]= plus two selection bits and an output =out[16]=:
#+BEGIN_SRC
Chip name: Mux4Way16
Inputs:    a[16], b[16], c[16], d[16], sel[2]
Outputs:   out[16]
Function:  If sel=00 then out=a, if sel=01 then out=b, ... etc.
#+END_SRC
Note what is special about this chip: *It takes 4 possible 16-bit inputs, and turns it into one 16-bit output.* The usefulness of a selection bit is now much more obvious!
*** 1.3 - Implementation
Primitive gates are our elementary building blocks. In particular, we will build an entire computing system off of just one primitive gate: =Nand=. The following primitive gates can be build using just Nand: =Nand -> Not -> And -> Or/Xor -> Mux/DMux -> Multi-bit primitives -> Multi-bit Mux -> Multi-way=
*** 1.4 & 1.5 - Perspective and Project
We use =Nand= as our single primitive as a means of teaching, though it is not the only way to build computer systems from the ground up. We can study /digital design/ or /logic design/ for more in-depth knowledge.
**** DONE Project 01 <<nand-project-01>>
([[file:~/git-repos/nand2tetris/01][completed project files)]]

- OBJECTIVE :: Implement all the logic gates presented in the chapter. The only building blocks that you can use are primitive Nand gates and the composite gates that you will gradually build on top of them.
- RESOURCES :: Use the hardware simulator provided by /nand2tetris/. All chips should be implemented in HDL, with accompanying tests. Some HDL files or test files are missing, and it is our job to figure out how to re-implement those.
- CONTRACT :: When loaded into the hardware simulator, our chip design should produce the outputs listed in the supplied =.cmp= file.
- STEPS ::
- Read Appendix A1 - A6.
- Go through the /hardware simulator tutorial/ parts I, II, and III.
- Build and simulate all the chips specified in =projects/01=.

<2019-01-16 Wed>
***** DONE Project log
CLOSED: [2019-01-16 Wed 08:52]
****** DONE And
CLOSED: [2019-01-15 Tue 15:34]
******* =builtIn= directory must be relative to a script's root directory or included in the script folder itself
****** DONE Or
CLOSED: [2019-01-15 Tue 15:31]
****** DONE Xor
CLOSED: [2019-01-15 Tue 16:25]
******* scratch
#+BEGIN_SRC
MINTERM a'b + ab' = f(a, b)
#+END_SRC
****** DONE Mux
CLOSED: [2019-01-15 Tue 16:25]
******* scratch
#+BEGIN_SRC
ALIAS sel = s
MINTERM: f(a, b, s) = a'bs + ab's' + abs' + abs
DISTRIBUTIVE:
  f(a, b, s) = a'bs + a(b's' + bs' + bs)
             = a'bs + a(b(s + s') + b's')
             = a'bs + a(b + b's')
             = a'bs + ab + ab's'
             = as' + bs
#+END_SRC
****** DONE DMux
CLOSED: [2019-01-15 Tue 20:23]
******* scratch
#+BEGIN_SRC
IN: in, sel
OUT: a, b
ALIAS x = in
ALIAS y = sel
MINTERMS(a): xy'
MINTERMS(b): xy
#+END_SRC

*minterms/maxterms can be isolated by output and then superimposed*
****** DONE And16
CLOSED: [2019-01-15 Tue 20:35]
****** DONE Or16
CLOSED: [2019-01-15 Tue 20:37]
****** DONE Mux16
CLOSED: [2019-01-15 Tue 20:40]
****** DONE Mux4Way16
CLOSED: [2019-01-16 Wed 08:30]
******* scratch
*logic design involves a lot of looking for bitwise patterns and applying gradual abstractions*
****** DONE Mux8Way16
CLOSED: [2019-01-16 Wed 08:36]
****** DONE DMux4Way
CLOSED: [2019-01-16 Wed 08:46]
****** DONE DMux8Way
CLOSED: [2019-01-16 Wed 08:52]
*** Appendix A (A1 - A6): Hardware Description Language (HDL)
**** A.1 - HDL Program Example
[[a1-fig-a.1][Figure A.1]] specifies a chip that accepts two three-bit numbers and outputs whether they are equal or not.

#+BEGIN_SRC
Chip name: Eq3
Inputs:    a[3], b[3]
Outputs:   out
Function:  If a=b then out=1 else 0

CHIP Eq3 {
  IN a[3], b[3];
  OUT out;
  PARTS:
    Xor(a=a[0], b=b[0], out=c0);
    Xor(a=a[1], b=b[1], out=c1);
    Xor(a=a[2], b=b[2], out=c2);
    Or(a=c0, b=c1, out=c01); /* check if first bit and second bit are equal */
    Or(a=c01, b=c2, out=neq); /* check if first, second, third bit are equal */
    Not(in=neq, out=out);
}
#+END_SRC
/Figure A.1. <<a1-fig-a.1>>/
***** HDL API
Ths HDL bundled with the book contains a standard library =builtIn=. Parts can be referenced from this library by using =BUILTIN [built-in component]=.
** Chapter 2: Boolean Arithmetic
[2019-01-16 Wed 18:25]

In this chapter we build gate logic designs that represent numbers /and perform arithmetic operations on them/. We will go from all the basic gates we did in chapter 1, all the way to an *Arithmetic Logic Unit (ALU)* at the end of the chapter! In the following chapters we will build up to a fully functioning CPU.
*** Coursera Unit 2.1: Binary Numbers
In previous chapters, we've worked only with turning boolean values into more boolean values. However, binary can be used to represent "normal" arithmetic just as in decimal or other number systems.
*** Coursera Unit 2.2: Binary Addition
(this is fundamental and for the most part i know all of this)
*** Coursera Unit 2.3: Negative Numbers
We know that an =n=-digit /unsigned/ binary number can represent =2^n= values. For example, a 3-bit bus can have 8 (=2^3=) possible values.

That happens to be the same for /signed/ binary numbers. All we have to do is look at the leftmost bit; if it's =1=, then the number is negative, else it's positive.
**** 2's complement - Calculating signed binary numbers
***** Negation
An =n=-bit negative number =-x= can be thought of as =2^n - x=.
***** Bitwise negation
To negate a number in binary, we use *2's complement*. This is done by taking the /1's complement/ (flip all the bits) and adding 1:

#+BEGIN_SRC
3 = 0b0011
-3 = ^0b0011
   = 0b1100 + 1
   = 0b1101
#+END_SRC
*** Coursera Unit 2.4: ALU
The ALU is the brain-child of John Von Neumann. In Von Neumann Architecture,

=[INPUT] -> [MEMORY] <-> [CPU: {ALU | CONTROL}] -> [OUTPUT]=

the ALU exists within the CPU and is a central part in communicating with a computer's memory and output.
**** ALU specification
#+BEGIN_SRC
Chip name: ALU
Inputs:    in1, in2, f (where f is one of a family of pre-defined logical functions)
Outputs:   f(in1, in2)
Function:  Dependent on f
#+END_SRC
**** The Hack ALU
We will be building a Hack Computer in this course, so let's build a Hack ALU!

Hack ALU specification:
#+BEGIN_SRC
Chip name: HackALU
Inputs:    x[16], y[16], zx, nx, zy, ny, f, no
Outputs:   out[16], zr, ng
Function:  Many pre-defined functions defined by control bits
#+END_SRC
:w

The six control bits =zx, nx, zy, ny, f, no= define a /directive/ for the Hack ALU. It will compute many functions based on their input; for example, =000111= tells the ALU to compute =y - x=.
**** Hack ALU control bits
- =zx= - =if zx then x\=0=
- =nx= - =if nx then x\=!x=
- =zy= - =if zy then y\=0=
- =ny= - =if ny then y\=!y=
- =f= - =if f then out\=x+y else out\=x&y=
- =no= - ~if no then out\=!out~

The six control bits combine a /superposition/ of each of the functions specified by each bit. That is: =F(x, y) = z(x) + n(x) + z(y) + n(y) + f(x, y)=. This means that *the Hack ALU can compute any of 64 different function combinations.*
***** Example: Compute !x
- IN :: ~x=0b1100~ ~y=1011~
- CONTROL BITS :: =001101=

#+BEGIN_SRC
n(x) = 0: x = 1100
z(x) = 0: x = 1100
n(y) = 1: y = 0000
z(y) = 1: y = 1111
f(x, y) = 0:
  x & y = 1100
no = 1: out = 0011 === !x
#+END_SRC
***** Caveat
The ALU is just an implementation /of an abstraction/ of the previous basic logic gates we've created before. There is nothing too magical about it, other than the fact that somebody decided to combine a bunch of (very useful) bitwise functions into one unit.
**** Output control bits
- =zr= - ~if out=0 then zr=1 else 0~
- =ng= - ~if out<0 then ng=1 else 0~
***** Caveat
This becomes important a bit later down the line when we build a CPU!
**** Perspective
The Hack ALU is ideal for teaching purposes because of its simplicity, elegance, and ease of implementation. The bitwise functions it covers are fairly straightforward; they are visibly based off of early abstractions.

As we said before, the ALU is just putting a bunch of our previous chips into one chip!
*** Project 02 
- GIVEN :: All the chips built in Project 01!
- OBJECTIVE :: Build the a =HalfAdder=, =FullAdder=, =Add16=. =Inc16=, and =ALU=.
  - Note that these chips are all computational chips, going from simple to more complex.
  - Going from our previous example, we can see the trends we've been emphasizing regarding computational chips being simple extensions of basic logic gates. For example:
    - A =HalfAdder= has two outputs, =sum= and =carry=. Its truth table indicates that it can be implemented with just two basic chips: ~sum(a, b) = Xor(a, b)~ and ~carry(a, b) = And(a, b)~.
**** scratch
***** DONE HalfAdder
CLOSED: [2019-01-17 Thu 09:28]
+-----+-----+-----+-----+
|a    |b    |sum  |carry|
+-----+-----+-----+-----+
|0    |0    |0    |0    |
|0    |1    |1    |0    |
|1    |0    |1    |0    |
|1    |1    |0    |1    |
+-----+-----+-----+-----+
#+BEGIN_SRC
MINTERMS(sum):   a'b + ab'
MINTERMS(carry): ab
#+END_SRC
***** DONE FullAdder
CLOSED: [2019-01-17 Thu 09:39]
+-----+-----+-----+-----+-----+
|a    |b    |c    |sum  |carry|
+-----+-----+-----+-----+-----+
|0    |0    |0    |0    |0    |
|0    |0    |1    |1    |0    |
|0    |1    |0    |1    |0    |
|0    |1    |1    |0    |1    |
|1    |0    |0    |1    |0    |
|1    |0    |1    |0    |1    |
|1    |1    |0    |0    |1    |
|1    |1    |1    |1    |1    |
+-----+-----+-----+-----+-----+
#+BEGIN_SRC
MINTERMS(sum):   a'b'c + a'bc' + ab'c' + abc
  = a'(b'c + bc') + a(b'c' + bc)

MINTERMS(carry): a'bc + ab'c + abc' + abc
  = a(b'c + bc' + bc) + a'bc
  = a(b'c + b) + a'bc
  = ab'c + ab + a'bc
  = ab + ac + bc
#+END_SRC
***** DONE Add16 (16-bit adder)
CLOSED: [2019-01-17 Thu 09:50]
chain together a bunch of full adders
***** DONE Inc16 (16-bit incrementor)
CLOSED: [2019-01-17 Thu 09:52]
***** DONE ALU
CLOSED: [2019-01-17 Thu 10:16]
****** Chapter 2.3 - Implementation
This ALU can be reduced to implementing simple Boolean operations based on the ALU's six control bits. To start:
******* DONE implement a 16-bit input according to =nx= and =zx=
CLOSED: [2019-01-17 Thu 10:08]
******* DONE implement a 16-bit input according to =ny= and =zy=
CLOSED: [2019-01-17 Thu 10:08]
******* DONE pipe the results of =nxzx= and =nyzy= into the remaining input pins
CLOSED: [2019-01-17 Thu 10:16]
*** Perspective
*In any given computer, the overall functionality of the hardware/software platform is delivered jointly by the ALU and OS that runs on top of it.* When designing a new computer system, the decisions made when designing an ALU are a constant cost/performance tradoff.

*The general rule is that hardware implementations of arithmetic/logic are more expensive, but higher performing. Software abstractions are the opposite.*

The Hack ALU built in this course is designed to build off of previous chapters, and won't necessarily reflect most common ALU design decisions.
** Chapter 3: Sequential Logic
Chapters 1 and 2 covered /combinational chips/, in that the functions they compute depend solely on their input values. They are great for fast, high-performing requirements, but are unviable if we need our chips to maintain /state/.

/Sequential chips/ are what memory devices are made of; memory chips by definition are stateful. This chapter introduces the concepts of *synchronization*, *clocking*, and *feedback loops*, all of which are used to manipulate bits to be stateful. The name "sequential" comes from the fact that a sequential chip's output depends also on what was input in the /sequence/ before the current one.

We will start by building a very low-level sequential gate called a *flip-flop*. Flip-flops can be thought of as the building blocks for most sequential chips.
*** 3.1 - Background
Sequential logic chips are based on memory. Memory is based on time; we can remember /now/ something that happened /before/. *To implement memory, we must "implement" time.*
**** The Clock
In most computers, the passage of time is represented by a master clock which constantly alternates between two signal states. The output of this clock is fed to every sequential chip throughout an entire computer platform. We call the phases of this clock /low-high/, /0-1/, /tick-tock/, etc. Where ~out(0) = tick~ and ~out(1) = tock~.
**** Flip-Flops
Also called *DFFs* (/data flip-flops/). A DFF's interface consists of a single-bit data input and a single-bit data output, along with a clock input that is continuously changing. Taken together, the =data= input and =clock= input allow the DFF to implement some function ~out(t) = in(t-1)~. *A DFF simply outputs the input from the previous time cycle.*

DFFs are what we use as an elementary /stateful unit/. A very common example is a /register/.
**** Registers
A *register* is a storage device that can "remember" a value over time, implementing the storage behavior ~out(t) = out(t-1)~.

This means that *a register can be implemented from DFF simply by feeding the output of the DFF back into the input*. In order for a register to be able to handle both ~out = in(t-1)~ (write functionality) and ~out = out(t-1)~ (read functionality), we must use a conditional directive. Fortunately we can do this with a multiplexor, whose sole purpose is to select read/write based on a =load= variable.

Like in many of our low-level abstractions, once we've figured this out, we can make registers of any size, or /width/. The multi-bit contents of a multi-bit register are sometimes called /words/.
**** Memories
Once we have the ability to represent words, we can proceed to build /memory banks/ of arbitrary length. In order to build *RAM*, for example, we can simply stack together a whole bunch of registers.
***** Random-access memory (RAM)
The distinguishing property of RAM comes from the "random" part. It should be able to access randomly chosen words; *any word in the memory, /irrespective of its physical location/, should have the same access speed as any other word*. This requirement can be satisfied as follows:

1. We assign each word in the /n/-register RAM a unique /address/.
2. Alongside the /n/-register RAM, we build a gate logic design that, given an address =j=, can select the individual register with that same address.
****** RAM architecture
A classical RAM device accepts three inputs: *data*, *address*, and *load bit*. The purpose of each of these pins:

- The /address/ specifies which RAM register should be accessed in the current time step.
- The /load bit/ specifies whether to *read* (i.e. access ~out = out(t - 1)~) or *write* (i.e. access ~out = in(t - 1)~).
  - In the case of a read operation, the RAM's output immediately emits the value of the selected register at =&j=.
  - In the case of a write operation, the register at =&j= saves the data provided by the data bit in the current time step.
- The /data/ input specifies what should be written to a memory address in the case of a write operation.

The basic design paramters of a RAM device are its data /width/ (register capacity/max. word size) and its /size/ (total number of words in memory). For reference, modrern computers typically utilize 32-bit- or 64-bit-wide RAMs whose sizes are up to billions of words.
**** Counters
A /counter/ is a sequential chip whose state is an integer number that increments every time unit. Its characteristic is ~out(t) = out(t - 1) + c~, where =c= is the amount by which to increment the count.

Implementation of a counter is simple; it requires only one register in series and positive feedback with an incrementor. The load bit of a counter is usually not utilized unless we need to manually write a value to the counter's memory, or otherwise alter it; any combinational chip can be used to affect the load bit of this counter.
**** Overview
All of the chips we've discussed so far are /sequential/. It turns out that all sequential chips employ DFF gates at some level of the abstraction.

Technically speaking, this is done by forming feedback loops in combination with a selection directive, typically a multiplexor.

*Combinational chips change their outputs with their inputs*, meaning they are zero-order with respect to time--~f(...in) = out(...in)~.

*Sequential chips change their outputs with their inputs /and/ with respect to time*--~f(t, ...in) = out(t, ...in)~. The term "sequential" also implies that they may only change w.r.t time, at most, every one clock cycle.
***** Caveat
Sequential chips like this are modeled /discretely/ (as in discrete math). If measured and modeled in continuous time, their outputs would actually be incredibly unstable, thus we choose to implement chips which are deterministic to exactly one clock cycle.

The advantage of this is that we get to model /every/ part of the computer architecture in a discrete time model, with the same deterministic properties applying for every part of our system. This proves crucial in later tasks like scheduling, context, and parallel computation (not threading!).

Low-level "race conditions" like in inputting data to an ALU (combinational) might pose problems if we didn't use sequential chips in some form or another. However, because a computer architecture is absolutely dependent on sequential devices, we don't have to care about these race conditions. All we need to do is design the clock cycle to be deterministic, in that *a clock cycle is slightly longer than the time it takes for a bit to travel the longest distance from one chip to another*, and only dealing with changes in state at the top of every clock cycle
*** 3.2 - Specification
The chips specified in this section:

- Data-flip-flops (DFFs)
- Registers (based on DFFs)
- Memory banks (based on registers)
- Counter chips (also based on registers)
**** 3.2.1 - Data-Flip-Flops
A DFF has a single-bit input and output. Specification:
#+BEGIN_SRC
Chip name:     DFF
Inputs:        in
Outputs:       out
Function:      out(t)=in(t-1)
Comment:       This clocked gate has a built-in implementation.
#+END_SRC

*DFFs are like the "sequential version of =Nand= gates"*, in that many sequential chips are really just a bunch of DFFs put together.

***** Fixed-time updating
At the top of each clock cycle, all DFFs in a computer system commit to their inputs during the previous time step. At all other times, the DFFs are "latched", meaning that any changes in their inputs don't immediately affect their outputs (until the next clock cycle).
**** 3.2.2 - Registers
A single-bit register, or /binary cell/, is designed to store a single bit of information. The chip interface consists of an data pin, load pin, and output pin. Specification:
#+BEGIN_SRC
Chip name:     Register
Inputs:        data, load
Outputs:       out
Function:      if load(t-1) out(t)=in(t-1) else out(t)=out(t-1)
#+END_SRC
***** Multi-bit registers
The implementation is nearly identical.
#+BEGIN_SRC
Chip name:     Register
Inputs:        data[16], load
Outputs:       out[16]
Function:      if load(t-1) out(t)=in(t-1) else out(t)=out(t-1)
#+END_SRC
**** 3.2.3 - Memory
A direct-access memory unit (i.e. RAM) is an array of =n= =w=-bit registers equipped with direct access circuitry (each of =n= cells is given an address and can hold a word of size =w=).

The RAM we will be building will be 16-bits wide, but will have varying sizes: =RAM8=, =RAM64=, =RAM512=, =RAM4K=, and =RAM16K=. All these chips have the same API:
#+BEGIN_SRC
Chip name:     RAMn // n = size, k = number of required address bits
Inputs:        in[16], address[k], load
Outputs:       out[16]
Function:      if load(t-1) then RAM[address(t-1)](t)=in(t-1)
#+END_SRC

***** Read/write
****** Read operations 
To read the contents of register number =m=, we send =&m= as the address input. The RAM's direct-access logic well select that register and emit its stored value to the output. *This operation is combinational*.

****** Write operations
To write a value =d= to the register =m=, we send =&m= into the address input and set the load bit to =true=. Direct access logic will again select that register, then store a new value =d=. The next read operation that occurs will cause a referenced =uint_t m* = d=. *This operation is sequential*.


**** 3.2.4 - Counter 
Consider a counter chip designed to contain the address of the instruction that the computer should fetch and execute next (/this falls under scheduling(?)/). In most cases, the counter must increment itself by 1 in each clock cycle, causing the computer to fetch the next instruction in the program. In other cases, such as a =jump= instruction, we want to be able to arbitrarily set the counter to some time step =n=, then have it continue its default behavior by then incrementing to =n+1=, =n+2=, etc. If there is any non-sequential (aka we need to jump, not sequential as in discrete time) /The only way we can implement this behavior is with a "loadable" and "resettable" counter./

Thus, we choose to implement counters similar to registers. They have two additional input pins, =inc= and =reset=. =inc= will cause the counter to increment its count by 1 if set to =true=, while =reset= will reset the counter to =0= if set to =true=. The =load= pin now serves so that we can affect the output with a multiplexed input fed to =in.=
#+BEGIN_SRC
Chip name:     PC // 16-bit counter
Inputs:        in[16], inc, load, reset
Outputs:       out[16]
Function:      if reset(t-1) then out(t)=0 else if load(t-1) then out(t)=in(t-1) else if inc(t-1) then out(t)=out(t-1)+1 else out(t)=out(t-1) 
#+END_SRC
*** 3.3 - Implementation 
**** Flip-Flop 
DFF gates can be implemented from lower-level logic gates. However, in this book we treat DFFs as primitive gates.

**** Register
Basically DFFs with positive feedback and controlled by a multiplexer.

**** Memory 
Combine =n= =w=-wide registers to make a memory bus of size =n=. We must provide this memory with a direct access system in order to read/write from any address in memory; this is done via an =address= pin. The =load= pin controls read/write; /read/ operations are combinational and take effect immediately upon access, while /write/ operations are sequential and take effect at the top of the next time step. The length of our input should be sufficient to access all =n= registers in memory; that is, if =n = 2^x=, then =input= should be =x=-bits long.

**** Counters 
A =w=-bit counter consists of a regular =w=-bit register plus combinational logic. The combinational logic can:

1. Compute the counting function (incrementor)
2. Put the counter in the right operating mode (=load=, =reset=, =inc=)

*** 3.4 - Perspective 
In this chapter, we considered the flip-flop to be the most primitive building block of all computer memory systems.

The usual approach in other books is to approach flip-flops as non-primitive, first starting from =Nand= gates as we have before. This requires some knowledge of controlling clock cycles and understanding of the effect of feedback loops on combinatorial circuits--in order to get to the point quickly, we just jump ahead to a stable flip-flop as our base.

Also, memory devices of modern computers /are not always constructed from standard flip-flops/. Instead, modern memory chips are usually carefully optimized and exploit the physical properties of the storage technology being used.

Other than these low-level details, everything that is considered an abstraction over flip-flops still remains standard today.

*** 3.5 - Project 03 
<<nand-project-03>>
[2019-01-18 Fri]
- GIVEN :: Hardware simulator, everything from this chapter and previous chapters.
- OBJECTIVE :: Build all the chips in this chapter. The only building blocks we can use are primitive DFF gates, chips that we will build on top of them ourselves, and chips described in previous chapters.

**** scratch 

***** DONE Bit (1-bit register) 
- State "DONE"       from "TODO"       [2019-01-18 Fri 11:06]
***** DONE Register (n-bit register)
- State "DONE"       from "TODO"       [2019-01-18 Fri 11:10]
***** DONE RAM8
- State "DONE"       from "TODO"       [2019-01-18 Fri 11:25]
***** DONE RAM64
- State "DONE"       from "TODO"       [2019-01-18 Fri 11:38]
***** DONE PC
- State "DONE"       from "TODO"       [2019-01-18 Fri 12:02]
conditions in low-level code often imply hierarchy

hierarchy in HDL starts from the lowest conditional clause and travels up
***** DONE RAM512
- State "DONE"       from "TODO"       [2019-01-18 Fri 12:10]
***** DONE RAM4K
- State "DONE"       from "TODO"       [2019-01-18 Fri 12:20]
***** DONE RAM16K

- State "DONE"       from "TODO"       [2019-01-18 Fri 12:20]
*** Appendix A (A7) - Sequential Chips 
**** A.7.1 - The Clock 
The simulator models the progression of time by supporting two operations called /tick/ and /tock/. They simulate a series of /time units/. Each /tick/ ends the first phase of a time unit and starts the second phase, while /tock/ ends the second phase of the current time unit and starts the first phase of the first.

During all /ticks/, the inputs of each sequential chip in the architecture are read and affect the chip's internal state.

During all /tocks/, the outputs of the chip are set to new values. The values of the output pins, regardless of a read/write operation, are deterministic to the end of each /tock/.

**** A.7.2 - Clocked Chips and Pins 
We can specify whether a pin should be clocked or not by =CLOCKED pin=. A =CLOCKED= pin will behave sequentially.

***** Caveat 
Any high-order pin =P= may have some lower-level pin implementation =Q=, that is =P= is an abstraction over =Q=. /if =Q= or any other child of =P= is clocked, then =P= is also clocked./
** Chapter 4: Machine Language 
A computer can be described /constructively/, by layout out its hardware platform and explaining how it's built from low-level chips.

It can also be described /abstractly/, by specifying its higher-level machine language capabilities. This is where the fun part starts. By focusing on low-level machine language code, we can understand how to manipulate the computer to run /any/ machine language program and complete our general-purpose build.

*Machine language* is the first line in the computer enterprise where hardware and software meet. It is a formalism designed to code low-level programs as a series of machine instructions. Because it is the first instance where abstract code is transformed into actual physical activity, *machine language can be thought of as both a programming tool and an integral part of computer hardware*.

*** 4.1 - Background 
**** 4.1.1 - Machines 
A /machine language/ can be viewed as a formalism designed to manipulate /memory/ using a /processor/ and a set of /registers/.

***** Memory  
The term /memory/ refers loosely to the collection of hardware devices that store data and instructions in a computer.

From a programmer's standpoint, all memories are identical. All have some word/location /width/ and an /address/. We're probably used to accessing memory in this way via =Memory[address]=.

***** Processor
The processor is normally called the /central processing unit (CPU)/. We have implemented the CPU in the past by designing an ALU and its control outputs. CPUs are capable of a fixed set of elementary operations, namely those defined by the ALU.

The difference between the ALU and the CPU is that the CPU gets its inputs either from memory or from user input, and can also write to memory or some other output. Thus, it interfaces with those two parts in Von Neumann's architecture rather than being isolated.

***** Registers
Because memory access becomes gradually slower as it gets more nested (need to mux/demux several times the more nested a bus gets), we often want to keep some high-speed, "lower-order" local memory close to the processor. This concept should be familiar: Oftentimes it is implemented as a *stack* or *heap*, depending on the higher-level language implementation.

**** 4.1.2 - Languages 
A machine language program is a series of coded instructions. For example, a typical instruction for a 16-bit machine might be: =1010001100011001=.

What does this mean? We don't know, at least without context! One possible implementation:

Each instruction might consist of four bytes, each of which contains some meaningful information. The first byte =1010= might be a CPU operation, and the remaining bytes may represent operands. Imagine that this is Lisp:

#+BEGIN_SRC lisp
(+ 3 1 9); +=1010, 3=0011, 1=0001, 9=1001 
#+END_SRC

We might end up compiling a Lisp command such as the one above down to machine code just as the 16-bit instruction says. The thing is, *the implementation of machine code is 100% dependent on the hardware architecture beneath it*.

***** Assembly
This is precisely the reason we prefer to think one step above machine language, with *assembly language*. We can more closely understand machine code if we abstract it by one level. For example, the instruction =1010001100011001= can be thought of in (Hack) ASM as:

#+BEGIN_SRC asm
ADD R3, R1, R9
#+END_SRC

The code above is much more easily understood now. It turns out we were right about the instruction =1010= representing =ADD=, however =3=, =1=, and =9= turned out to be /register addresses/, not word literals. In any case, ASM is significantly easier to work with than machine code and we will be relying on it to build the rest of our software implementation.

**** 4.1.3 - Commands 
***** Arithmetic and logic operations 
Like we've learned so far, every computer is required to perform basic arithmetic operations like addition and subtraction (multiplication and division are just repeated addition and subtraction) as well as Boolean logic operations. Some Hack ASM syntax:
#+BEGIN_SRC asm
ADD R2, R1, R3 ;; R2<-R1+R3, or "value at R2 gets value at R1 plus value at R3"
ADD R2, R1, foo ;; approximate C: int* r2 = &r2_addr; r2 = r1 + foo
AND R1, R1, R2 ;; approximate C: uint_8t r1 = r1_value; r1 = r1 & r2
#+END_SRC

***** Memory access
Most assembly commands that actually manipulate memory are in the form of =LOAD= and =STR= (store) commands. In order to actually access memory using those commands, we have different /addressing modes/. They are not necessarily globally adopted. Some common ones:

****** Immediate addressing
Immediate addressing is simply piping a literal memory address into our code. =LOAD R1, 67= writes the value at memory address =67= to register =R1=.

****** Direct addressing 
When we refer to a memory address by an alias, we use direct addressing. Say we defined =mem[67]= to have an alias =foo=. The resulting code: =LOAD R1, foo=

****** Indirect addressing 
This is how we handle pointers. Let's take this typical line of C code:
#+BEGIN_SRC c
int x;
int k = 6; // size of array
int* foo = malloc(k * sizeof(int));

int j = 4; // index of array value we wish to access
x = *(foo + j); // x gets value of foo[j]
#+END_SRC

In assembly:
#+BEGIN_SRC asm
;; let's just say we've predefined our memory allocation and array indices
ADD R1, foo, j ;; R1 gets foo+j
LOAD* R2, R1 ;; write pointer-to-R1 to R2
STR R2, x ;; alias R2 to x
#+END_SRC

****** Flow of control 
AKA /jump/ and /conditional/ directives.

******* Unconditional jumps
Defined by =JMP=. Usage: =JMP R1=. Simply specify instruction register to jump to. 

******* Conditional jumps 
Defined by several conditional directives, operating mostly on comparison-based clauses.

*** 4.2 - Hack Machine Language Specification
**** 4.2.1 - Overview
The Hack computer is a von Neumann platform. It is a 16-bit machine consisting of a CPU, two separate memory modules serving as /instruction memory/ and /data memory/, and two memory-mapped I/O devices: a screen and a keyboard.

***** Memory Address Spaces
We define two distrinct memory regions: an *instruction memory* and a *data memory*. Both are 16-bits wide and have a 15-bit address space, meaning that the maximum addressable size of each memory is 32k 16-bit words.

/Instruction memory/ holds programs that will be directly executed by the computer. It is read-only (by the computer), and programs are loaded into it externally (aka physically).

/Data memory/ is the regular storage unit of the computer.

***** Registers 
We have two 16-bit registers called =D= and =A=. They can be manipulated explicitly by instructions like ~A=D-1~ or ~D=!A~, both of which are either arithmetic or bitwise logic operations.

=D= is used solely to store data values, while =A= is both a data register /and/ an address register, which means that the contents of =A= can be interpted either as purely a data value, equivalent to an address in data memory, or equivalent to an address in instruction memory.

****** Using =A= as a data pointer 
Hack syntax mandates that memory access instructions operate on an implicit memory location named =M=, for example, ~D=M+1~. =M= /always/ refers to the memory word whose address is the current value of the =A= register. Thus, if we want =M= to point to memory address =&412=, we must set =A= to the literal value =412=.

****** Using =A= as an instruction pointer
In order to effect flow of control, we can also use =A= to operate on instruction memory. A =JMP= instruction in Hack does not specify a particular address. Instead, jump instructions /also/ implicitly refer to the literal value of =A= to identify which instruction pointer to jump to.

****** A-instructions and C-instructions 
Any memory operations in most machine languages, Hack included, requires two operations: One to fix the address we want to operate on, and another to actually do that operation. In Hack, we have /address instructions/ called *A-instructions*, and /compute instructions/ called *C-instructions*, which do exactly that.

**** 4.2.2 - The A-Instruction 
*The A-instruction is used to set the =A= register to a 15-bit value.*
#+BEGIN_SRC
A-instruction:  @value  // where `value` is a non-negative decimal number
                        // or a symbol referring to such number
#+END_SRC

This instruction causes the computer to store the specified value in the =A= register--=@5=, for example, stores the literal word =5= in the =A= register.

The =A= instruction is used for three different purposes:

1. It provides the only way to enter a constant into the computer under program control.
2. It sets the stage for a subsequent =C= instruction designed to manipulate a certain data memory location.
3. It sets the stage for a subsequent =C= instruction that specifies a jump.

To see =A= instructions in action, here's some C code compared with Hack machine language!
#+BEGIN_SRC c
// increments from 1 to 100
int i = 1;
int sum = 0;

while (i <= 100) {
  sum += i;
  i++;
}
#+END_SRC

#+BEGIN_SRC nand2tetris
  @i // `i` refers to some address
  M=1
  @sum // `sum` refers to some address
  M=0 ; sum=0
(LOOP)
  @ni
  D=m // D=i
  @100
  D=D-A // D=i-100
  @END
  D;JGT // if (i-100)>0 goto END
  @i
  D=M
  @sum
  M=D+M // sum=sum+i
  @i
  M=M+1 // i=i+1
  @LOOP
  0;JMP // goto LOOP
(END)
  @END
  0;JMP // infinite loop, standard in hack to "terminate" programs
#+END_SRC

Some Hack conventions:

- We use uppercase to represent labels and lowercase to represent variables.
- All variables resolve to physical memory addresses.

**** 4.2.3 - The C-Instruction 
The *C-instruction* is what gets almost everything done in the Hack machine language. It answers three questions:

1. What do you want to compute?
2. Where do you want to store the computed value?
3. What do you want to do next?

#+BEGIN_SRC
C-instruction:  dest=comp;jump  // `dest` or `jump` may be empty
                                // if `dest` is empty, emit `=`
                                // if `jump` is empty, emit `;`
BINARY: [1, 1, 1, a] [c1, c2, c3, c4] [c5, c6, d1, d2] [d3, j1, j2, j3]
#+END_SRC

The leftmost bit is the C-instruction code, which is 1. The next two bits are insignificant as they aren't used.

The /comp/ field (=a=, =c1-=c6=) is a 6-bit array which instructs the ALU what to compute. The /dest/ field (=d1=-=d3=) instructs where to store the computed value (ALU output). The /jump/ field (=j1=-=j3=) specifies a jump condition, namely which command to fetch and execute next.

***** The computation specification 
If we look back to chapter 2, we'll see that the Hack ALU has six control pins which affect what computation the ALU will be doing. The /computation/ field specifies seven control pins via pins =a= and =c1-c6=, meaning we can execute one of 128 possible functions based on this field.

Suppose we want to set a register =x= to 2, and then compute =D-x=? The corresponding code would be:
#+BEGIN_SRC nand2tetris
@x // assuming `x` is a valid register
M=2
D=D-A
#+END_SRC 

The corresponding /C-instruction/ we used in that example was =1110 1001 1000 0000=.

***** The destination specification 
The /destination specification/ specifies *where* to put the results of our computation. It is a 3-bit array, where the first and second =d=-bits specify whether to store the computed value in the =A= register or =D= register, while the third bit specifies whether or not to store the computed value in =M=.

What if we want to increment the value of =Memory[7]=, and also store the value in =D=? The corresponding machine language instruction would be:

#+BEGIN_SRC binary
0000 0000 0000 0111 ;; @7
1111 1101 1101 1000 ;; MD=M+1
#+END_SRC

A table of =d=-field mnemonics:
+----------------+----------------+----------------+---------+----------------------+
|d1              |d2              |d3              |Mnemonic |Destination           |
+----------------+----------------+----------------+---------+----------------------+
|0               |0               |0               |null     |value not stored      |
|0               |0               |1               |M        |Memory[A]             |
|0               |1               |0               |D        |D register            |
|0               |1               |1               |MD       |Memory[A] and D reg.  |
|1               |0               |0               |A        |A register            |
|1               |0               |1               |AM       |A register and Mem[A] |
|1               |1               |0               |AD       |A reg. and D reg.     |
|1               |1               |1               |AMD      |A, M[A], D            |
+----------------+----------------+----------------+---------+----------------------+

***** The jump specification 
The /jump/ field of the C-instruction tells the computer what to do next. There are two possibilities:

1. The computer should either fetch and execute the next instruction in the program, or
2. It should fetch and execute an instruction from somewhere else in the program.
3. If #2 applies, then "somewhere else" refers to the value in the =A= register.

Whether or not a jump should actually materialize depends on the three =j=-bits /and/ on the ALU output value. This is because there are several jump commands which rely on the ALU output.

A table of =j=-field mnemonics: 
+----------------+----------------+----------------+---------+----------------------+
|j1              |j2              |j3              |Mnemonic |Effect                |
+----------------+----------------+----------------+---------+----------------------+
|0               |0               |0               |null     |no jump               |
|0               |0               |1               |JGT      |if out > 0 jump       |
|0               |1               |0               |JEQ      |if out = 0 jump       |
|0               |1               |1               |JGE      |if out >= 0 jump      |
|1               |0               |0               |JLT      |If out < 0 jump       |
|1               |0               |1               |JNE      |If out != 0 jump      |
|1               |1               |0               |JLE      |If out <= 0 jump      |
|1               |1               |1               |JMP      |unconditional jump    |
+----------------+----------------+----------------+---------+----------------------+

***** Conflicting uses of a register  
Key usesof the =A= register is to specify a /data memory/ location for a C-instruction's =c=-field, or to specify an /instruction memory/ location for a jump. Thus, because the =A= register can be used to store data related to both data memory and instruction memory, *we should not use =M= when referring to instruction memory*.

**** 4.2.4 - Symbols 
Assembly symbols can refer to memory addresses using either constants or symbols. We introduce those to assembly in three ways:

- Predefined symbols :: A special subet of RAM addresses can be referred to by any assembly program using the following:
  - Virtual registers :: =R0= to =R15= are predefined to refer to RAM addresses 0 to 15.
  - Predefined pointers :: =SP=, =LCL=, =ARG=, =THIS=, and =THAT= are predefined to refer to RAM addresses 0 to 4.
  - I/O pointers :: =SCREEN= and =KBD= refer to I/O pins, specifically =0x4000= (input) and =0x6000= (output).
- Label symbols :: These are user-defined which serve to label destinations of =goto= commands. They are usually surrounded by parentheses: =(LOOP)= and refer to a location in instruction memory.
- Variable symbols :: These are also user-defined. They are assigned RAM addresses sequentially, starting at address =16= (=0x0010=). 

**** 4.2.5 - Input/Output Handling 

***** Screen 
The Hack computer has a bitmapped 512x256 black/white screen, which is contained within a contingent block of memory starting at =0x4000=. Each row in the physical screen is represented by 32 consecutive 16-bit words. Thus, the pixel at row =r= from the top and column =c= from the left is stored at memory location: =RAM[0x4000 + r * 32 + c / 16]=. To write to the screen, simply set a screen bit to 1; to erase from the screen, set a screen bit to 0.

***** Keyboard 
The Hack computer interfaces with a physical keyboard via a single-word memory register, located at =RAM[0x6000]=. Whenever a key is typed, its ASCII code appears as a word at =0x6000=. When no key is being pressed, a =0= appears at that address. The Hack computer uses additional keycodes in addition to the ASCII specification; they are listed in the book.

**** 4.2.6 - Syntax Conventions and File Format 

***** Binary code files 
Stored under extention =.hack=. Each line consists of a sixteen-bit instruction. The binary code represented by the file's /n/th line is stored in address /n/ of instruction memory.

***** ASM files 
Stored under extension =.asm=.

***** Constants and symbols 
Constants must be non-negative and are always written in decimal notation. A user-defined /symbol/ can be any sequence of letters, digits, undescores, dots, dollar signs, or colons. Symbols can't begin with numbers.

***** Comments 
=//=

***** Whitespace
Don't worry about it!

***** Case conventions 
All ASM mnemonics should be written in uppercase. Variable names should be in lowercase.

*** 4.3 - Perspective 
The Hack machine language is almost as simple as machine languages get. Most computers have more instructions, more data types, more registers... more of everything.

We can describe Hack as a "1/2 address machine". Since there's no room to pack both an instruction code and a 15-bit address in the 16-bit instruction format, it basically takes twice as many instructions in Hack as it does another machine language. It is for this reason that Hack ASM mostly consists of =A=-instructions followed by =C=-instructions.

The /assembler/ is the piece of architecture that is responsible for compiling our ASM into machine code. We will tackle this in another chapter.

*** 4.4 - Project 
- OBJECTIVE :: Get a taste of low-level progrmaming in ASM, and get acquainted with the Hack computer platform. - CONTRACT :: Write and test the two programs as follows:
  - /Multiplication program/ =Mult.asm= :: The inputs of this program are the current values stored into =R0= and =R1=. The program computes =R0 * R1= and stores the result in =R2=.  We assume that ~R0 >= 0~, ~R1 >= 0~, and ~R0 * R1 < 32768~.
  - /I/O-Handling Program/ =Fill.asm= :: This program runs an infinite loop that listens to the keyboard input. When a key is pressed, the program blackens the screen (writes a "1" to every pixel). When no key is pressed, the screen is cleared. The screen should maintain its "on" state for as long as any key is being pressed and held. 

**** DONE =Mult= 
CLOSED: [2019-01-21 Mon 14:43]
- State "DONE"       from "TODO"       [2019-01-21 Mon 14:43]
**** DONE =Fill= 
CLOSED: [2019-01-21 Mon 14:43]






- State "DONE"       from "TODO"       [2019-01-21 Mon 14:43]
** Chapter 5: Computer Architecture 
We are now ready to take all the chips that we built in chapters 1-3 and integrate them into a general-purpose computer capable of running stored programs!

The computer we will build is called /Hack/, and it has two important virtues:

1. Hack is a simple machine that can be constructed in just a few hours.
2. Hack is sufficiently powerful to illustrate the key operating principles and hardware elements of any digital computer.

We will first start by introducing the *stoerd program* concept and *von Neumann architecture*; the Hack platform is one example of a von Neumann machine. We'll learn how to implement the Hack platform using the chips we have built thus far.

*** 5.1 - Background
**** 5.1.1 - The Stored Program Concept
The most unique feature of the digital computer is its versatility. It has finite hardware, yet it can perform a practically infinite array of tasks. This is the direct result of the /stored program/ concept.The basic idea is that hte computer is based on a fixed hardware platform, capable of executing a fixed repretroire of instructions. Yet at the same time, these instructions can be used and combined like building blocks, yielding arbitrarily sophisticated programs.

These programs are not embedded in the hardware. *These programs' code is stored and manipulated in the computer's memory, /just like data/*. This is where we begin to formally study computers using the term "software".

**** 5.1.2 - The von Neumann Architecture 
The stored program concept is a key element of many abstract and practical computer models, most notably the /universal Turing machine/ and the /von Neumann machine/. The von Neumann machine is a practical architecture and the conceptual blueprint of almost all computer platforms today, while the Turing machine is used mainly to analyze the logical foundations of computer systems.

The von Neumann architecture is based on a /central processing unit/ interacting with a /memory/ device, receiving data from some /input/ device, and sending data to some /output/ device. At the heart of this architecture lies the stored program concept: *The computer's memory stores not only the data that the computer manipulates, but also the very instructions that tell the computer what to do*.

**** 5.1.3 - Memory 
The memory of a von Neumann machine holds /data items/ and /programming instructions/. These are usually treated differently, and in some computers they are stored in separate memory units.

In spite of their different functions, both types of information are represented as binary numbers that are stored in the same generic random-access structure (RAM).

***** Data memory
High-level programs manipulate abstractions such as variables, arrays, and objects. These structures must be stored in some kind of memory, and in our case we choose to allocate /data memory/.

Once an individual word has been selected to form the data memory by specifying its address, it can be either /read/ from or /written/ to.

***** Instruction memory 
When translated into machine language, each high-level command becomes a series of binary words which represent the computer hardware's machine language. These instructions (high-level code) are stored in the computer's /instruction memory/.

In each step of the computer's operaation, the CPU /fetches/ a word from the instruction memory, decodes it, executes it, and figures out where to go next. 

**** 5.1.4 - Central Processing Unit 
The CPU is the *centerpiece of the computer's architecture*. It is in charge of executing the instructions of the currently loaded program, which tell hthe CPU to carry out various calculations, read/write values from/into memory, and to conditionally jump to other locations in instruction memory. The CPU executes these tasks using three main hardware elements: The /ALU/, a set of /registers/, and a /control unit/.

***** ALU
The ALU is built to perform all the low-level arithmetic and logical operations featured by the computer.

***** Registers 
The CPU is designed to carry out simple calculations /quickly/, and for this reason we use a memory array with limited nesting and with direct-access capability. These local registers are what allow fast computation speed.

***** Control unit 
A computer instruction is represented as a binary code, typically 16, 32, or 64 bits wide. Before an instruction can be executed, ti must be decoded, and the information embedded in it must be used to signal various hardware devices (ALU, registers, memory) how to execute the instruction.

The control unit is what does this instruction decoding; it is also responsible for figuring out which instruction to fetch and execute next.

The CPU operation can now be described as a repeated loop: *Fetch an instruction from memory, decode it, execute it, fetch the next instruction, and so on*. THe instruction execution may involve one or more of the following /micro tasks/: Have the ALU compute some value, manipulate internal registers, read a word from the memory, and write a word to the memory. In the process of executing these tasks, the CPU also figures out which instruction to fetch and execute next.

**** 5.1.5 - Registers 
Memory access is usually a slow affair. When the CPU needs to retrieve the contents of an address /j/ that is external from the CPU, the following process ensues:

1. /j/ travels from the CPU to the RAM's address input.
2. The RAM's direct-access logic selects the memory address whose address is /j/.
3. The contents of =RAM[j]= travel back to the CPU.

This is a round-trip affair. Fortunately, having registers /within/ the CPU remove the need for a round-trip. Because the registers are physically inside the CPU, it takes almost no time for the CPU to access them. Second, there are typically only a handful of registers, compared to millions of memory blocks located outside of the CPU.

Different CPUs employ different numbers and kinds of registers, and for different purposes. In some computer architectures, each register can serve more than one purpose:

***** Data registers 
These give the CPU short-term memory services. For example, when calculating =(a - b) * c=, we must first compute and remember the value of =a - b=; this is what a data register is used for, as a "temporary home" for the intermediate values we need to carry out a full calculation.

***** Addressing registers 
The CPU has to continuously access memory in order to read and write data. For this purpose, the literal values (e.g. in C, =&a=) of addresses of memory that must be accessed are kept in /addressing registers/. 

***** Program counter registers
When executing a program, the CPU must always keep track of the address of the next instruction that must be fetched from the program. This is usually kept in a special register called the /program counter/. This allows the CPU to behave in one of two ways: If the current instruction does not contain a =goto= instruction, the program counter's current value is used to determine the next instruction that must be fetched and executed. Otherwise, the =goto= location is written to the program counter.

**** 5.1.6 - Input and Output 
Computers interact with their external environments using a diverse array of I/O devices, including screens, keyboards, mice, printers... etc.

There are two reasons we do not concern ourselves with the anatomy of these devices. First, they are isolated pieces of technology, all of which require a unique understanding. Second, computer scientists have come up with ways to make all of these external media look exactly the same to the computer. The simplest trick in this art is called =memory-mapped I/O=.

The basic idea of memory-mapped I/O is to create a binary emulation of the I/o device, making it "look" to the CPU like a normal memory segment. Each I/O device is allocated an exclusive area in memory, becoming its "memory map".

In the case of an input device, the memory map is made to continuously /reflect/ the physical state of the device. In the case of an output device, the memory map is made to continuously /drive/ the physical state of the device.

When external events affect some input devices, certain values are written to certain locations in their memory maps, and likewise when internal events should cause external state changes.

*** 5.2 - The Hack Hardware Platform Specification
**** 5.2.1 - Overview
The Hack platform is a 16-bit von Neumann machine consisting of a CPU, two separate memory modules (/data/, /instruction/), and a screen and keyboard.

It executes programs that reside in its instruction memory. The instruction memory is a read-only device, and thus programs are loaded into it using some exogenous means (external disk or drive or something). This behavior is simulated.

The Hack CPU consists of the ALU, along with the /D/-register and /A/-register, as well as the program counter (PC). D and A are general-purpose registers that can be manipulated by arithmetic and logical instructions.

The Hack machine language is based on two command types: =C=-instructions for assignments and control flow, and =A=-instructions for loading data into the /A/-register. 

***** Computer operation per clock cycle 
The computer's architecture is wired in such a way that the output of the PC chip is connected to thea ddress input of the ROM chip. This way, the ROM chip always emits the word ROM[PC], namely, the contents of the instruction memory location whose address is pointed at by the PC. This value is called the *current instruction*.

The overall computer operation *during each clock cycle* is as follows:

****** Execute
Various bit parts of the current instruction are simultaneously fed to various chips inside the computer. If it's an /address instruction/ (MSB = 0), then the A-register is set to the 15-bit constant embedded in the instruction. If it's a /compute instruction/, then its underlying =a=, =c=, =d=, and =j= bits are treated as control bits that cause the ALU and registers to execute the instruction.

****** Fetch 
Which instruction to fetch next is determined by the jump bits of the current instruction, and by the ALU output. These values together determine whether a jump should occur. If so, the PC is set to the value of the A-register. Otherwise, it is incremented by 1. In the next clock cycle, the instruction that the program counter points at emerges from the ROM's output, and the cycle continues.

****** The fetch-execute cycle 
The Hack platform employs two kinds of instructions: An /address instruction/, which signifies the use of the A-register, and a /compute instruction/, which operates on the results of the previous address instruction. 

**** 5.2.2 - Central Proessing Unit
The CPU of the Hack platform is designed to execute 16-bit instructions according to the Hack machine language. It expects to be connected to both instruction memory and data memory.

**** 5.2.3 - Instruction Memory 
Direct-access ROM. Consists of 32K addressable 16-bit regiters.

**** 5.2.4 - Data Memory 
Direct-access memory. To read the contents of register =n=, we put =n= in the memory's =address= input and look at the =out= output. We utilize the =load= pin to specify whether to read (=0=) or write (=1=) to any given register.

***** Memory maps
The Hack platform uses a standard keyboard and screen as I/O. These devices interface with the computer's data memory, where memory maps are formed in order to execute control over these I/O devices. The screen is designed a memory map starting from address =0x4000=, while the keyboard is designated a memory map starting from address =0x6000=. For an input device, the contents of its memory map reflect the external state of the device. For an output device, the external state of the device reflects the contents of its memory map.

***** Overall memory 
The overall address space of the Hack platform is provided by a chip called /Memory/. The memory chip includes RAM and the screen and keyboard memory maps. These modules reside in a single address space that is then partitioned into four spaces:

- RAM is designated addresses =0= through =16383=.
- The screen is designated addresses =16384= through =24575=.
- The keyboard is designated addresses =24575= through (?).

**** 5.2.5 - Computer 
The topmost chip in the Hack hardware hierarchy is a complete computer system designed to execute programs written in the Hack machine language.

*** 5.3 - Implementation 
We build our chips with HDL and write programs for the computer in Hack ASM

**** 5.3.1 - The Central Processing Unit
The CPU implementation objective is to create a logic gate architecture capable of executing a given Hack instruction and fetching the next instruction to be executed. It involves designing /control logic/ which can perform the following:

- Instruction decoding :: Parse the instruction into its underlying fields, i.e. subsets of bits. We call these "control bits".
- Instruction execution :: Signal the various chip parts of the computer what they should do in order to execute the instruction. This is done by routing all control bits to their intended destinations.
- Next instruction fetching :: Figure out which instruction to execute next. THis decision depends on the jump bits of the instruction as well as two control bits emitted by the ALU.

***** Instruction decoding & execution
The 16-bit instruction loaded into the CPU's input pin can represent either =A= or =C= instructions. In order to figure out what the word means, we can break the instruction into sub-fields:

=i xx a cccccc ddd jjj=

- =i= :: represents the *instruction type*: If =i= is equal to 1, then the instruction is a =C= instruction. Else, it's an =A= instruction.

In the case of an =A= instruction, the remaining 15 bits form the memory address which should be accessed.
- =x= :: bits are always set to 1, as they are not used.
- a & c :: In the case of a =C= instruction, the =a= and =c= bits code the /comp/ part, which tell the ALU what function to compute. The =a= bit in particular tells the CPU whether to operate on the A or C-register.
- =d= :: represents the /destination/ field. It tells the CPU where to store the value computed by the =a= and =c= bits.
- j :: represents the /jump/ field. It tells the computer whether or not to execute a jump, and whether it should be conditional or unconditional. Conditional jumps are based on the value that is currently loaded into the =A= register.

The various fields of the instruction are routed simultaneously to various parts of the architecture, where they cause different chips to do what they need to in order to execute whatever instruction was given to the CPU. 

***** Next instruction fetching 
As a side effect of executing the current instruction, the CPU also determines the address of the next instruction and emits it via =pc=. The program counter determines what to do next. If we would like to =goto= a specific instruction memory address, we set the PC =load= to 1 and feed the desired address into the PC's =in= pin. Else, we set =load= to 0. We also have a =reset= pin with predictable behavior. The output of the PC is then used to determine the next instruction. This causes the following behavior:

#+BEGIN_SRC 
If jump(t) then PC(t) = A(t - 1) // where A is the value that was loaded into the A register last clock cycle
else PC(t) = PC(t - 1) + 1
#+END_SRC

**** 5.3.2 - Memory 
According to its specification, the =Memory= chip of the Hack platform is essentially a package of three lower-level chips: RAM16K, screen, and keyboard.

**** 5.3.3 - Computer 
The topmost =Computer= chip depends on the implementation and function of the =CPU= and =Memory= chips. The construction of the computer is then fairly straightforward.

*** 5.4 - Perspective 
Again (for like the 10th time this book I swear), the Hack computer is minimal as all HELL.

The Hack machine is *general-purpose*, not *dedicated*. Dedicated means like cash register or caluclator or SCADA system or PLC or something. Splitting data and instruction memory isn't normal, but Hack does it to teach the concept. All of this "dumbing down" is done to actually teach computer architecture and it is clearly working because I think I know what I'm doing now.

*** 5.5 - Project 
- Objective :: Build the Hack computer platform.
- Resources :: Hardware simulator and HDL.
- Contract :: The computer should be able to execute Hack ASM and stuff. Demonstrate this capability by running the three programs in Chapter 4.
- Component Testing :: test scripts BABY
- Test Programs :: yeah

Build the computer in the following order:

**** DONE Memory 
CLOSED: [2019-01-25 Fri 09:59]
- State "DONE"       from "TODO"       [2019-01-25 Fri 09:59]
Composed from =RAM16K=, =Screen=, and =Keyboard=.

**** DONE CPU 
CLOSED: [2019-01-25 Fri 14:08]
- State "DONE"       from "TODO"       [2019-01-25 Fri 14:08]
See book figure 5.9

***** scratch
TL;DR when dealing with complicated logic flowcharts, try to identify "composite" conditions and reduce them down to the lowest denomination

**** Instruction Memory 
Use built-in =ROM32K=.

**** DONE Computer 
CLOSED: [2019-01-25 Fri 14:44]
- State "DONE"       from "TODO"       [2019-01-25 Fri 14:44]
Use the other chips.
** Chapter 6: Assembler 
The first half of the book so far has dealt with a computer's *hardware platform*. The remaining chapters will deal with the computer's *software hierarchy*. We will be working our way up from the /assembler/ all the way up to a simple OOP language.

In this chapter we will learn exactly how to develop a /Hack assembler/ which is capable of generating binary code that can run as is on the hardware platform we built last chapter. Since the relationship between symbolic assembly commands and actual binary machine code is straightforward, writing in assembler, it turns out, is not difficult. One complication comes from allowing assembly programs to use symbolic references to memory addresses; in this case we must define a /symbol table/, a data structure which contains mapped pairs of symbols:addresses. 

As usual, the purpose of the Hack assembler is to demonstrate key software engineering principles used in the construction of any assembler.

The software projects that follow may be implemented in any programming language.

*** 6.1 - Background 
Machine languages are typically specified as either /symbolic/ or /binary/. Binary codes represent "actual" machine instructions, while symbolic codes... represent binary codes.

Because binary codes are typically broken down by bits, they can be easily translated into a symbolic language. For example, take =1100 0010 1000 0001 1000 0000 0000 0111=. Let's say that the left-most 8 bits represent an operation code, the next 8 bits represent a register, and the remaining 16 bits represent an address. The sentence here is (roughly) "Do this operation on this register and assign the result to this address".

We choose to use a "standard" or "best-practice" syntax to construct these symbolic languages. The above instruction could be translated, for example, to =LOAD R3 7=, in assembly. Because the relationship between assembly and binary codes are so close, it becomes relatively trivial to both /write/ assembly code and /compile/ it into machine code. 

Assembly code uses symbols in two ways:
- As variables :: The programmer can use symbolic variable names, and the translator will "automatically" assign them to memory addresses.
- As labels :: The programmer can "mark" various locations in the program with symbols. (=LOOP=, =START=, =END=, etc.)

**** Symbol Resolution
So how /exactly/ do we convert a symbolic program into a binary one?

We start by making two arbitrary rules: *The translated code will be stored into the computer's memory starting at address 0, and variables will be allocated to memory locations starting at address 1024*. (These rules are specific to the target hardware platform; they shouldn't be taken absolutely!) Next, we build a *symbol table*:

For each new symbol =xxx= encountered in the source code, we add a line (=xxx=, =n=) to the symbol table, where =n= is the memory address associated with the symbol according to our rules. Once the program's symbols have been completely parsed and the symbol table is complete, we use it to translate the program into binary.

***** Example
****** Assembly pseudocode 
// compute sum=1+...+100
  i=1
  sum=0
LOOP:
  if i=101 goto END 
  sum=sum+i
  I=i+1
  goto LOOP
END:
  goto END
#+END_SRC

****** Resulting symbol table 
|--------+----------------|
| symbol | memory address |
|--------+----------------|
| i      |           1024 |
| sum    |           1025 |
| LOOP   |           1026 |
| END    |           1027 |
|--------+----------------|

****** Caveat 
Complicated assembly commands (such as ~if i=101 goto END~) may translate into several machine instructions, and thus will end up occupying several memory locations.

**** The Assembler 
Before an assembly program can be executed on a computer, it must be translated into the computer's binary machine language. This is done by a program called the *assembler*. It takes as input a stream of assembly commands, and generates as output a stream of equivalent binary instructions.

Basically, it's a text-processing/tex-translation program. Programmers who write assemblers must be given the full documentation of the assembly syntax on the one hand, and the respective binary codes on the other hand. This contract is typically called the *machine language specification*.

For each symbolic command found in the assembly language, the following steps occur:

1. Parse the symbolic command into its underlying fields.
2. For each field, generate the corresponding bits in machine language.
3. Replace all symbolic references with numeric addresses of memory locations.
4. Assemble the binary codes into a complete machine instruction.

(Pro tip: The hard part is handling symbols)

*** 6.2 - Hack Assembly-to-Binary Translation Specification
**** 6.2.1 - Syntax Conventions and File Formats
***** File names 
Hack machine code files end in =.hack=. Hack ASM files end in =.asm=.

***** Binary code (=.hack=) files
A binary code file is composed of text lines, each consisting of a four-byte word. When compiled, each line =n= is stored at address =n= of instruction memory.

***** Assembly language (=.asm=) files 
An assembly language file is composed of text lines, each representing either an /instruction/ or a /symbol declaration/:
- Instruction :: an /A/ or /C/ instruction.
- Symbol :: This "marks" a location in instruction memory and binds that location to a user-defined symbol. For example, the symbol =(LOOP)= may be accessed by the /A/-instruction: =@LOOP=. 

***** Constants and symbols 
/Constants/ must be non-negative and written in decimal notation. A user-defined /symbol/ can be any sequence of letters, digits, underscores, dots, dollar signs, and/or colons that does not begin with a digit.

***** Comments 
=//=

***** Whitespace 
sike lol

***** Case conventions 
All assembly mnemonics are written in uppercase (=JGT=, =JEQ=, etc). Uppercase for labels, lowercase for variable names.

**** 6.2.2 - Instructions 
Instructions are either /A/ (addressing) or /C/ (computing). The specification:
***** /A/-instructions 
#+BEGIN_SRC 
Syntax:    @value
Binary:    0vvv vvvv vvvv vvvv
Comments:  The first bit (0) signifies an A-instruction. The remaining bits represent the address which must be accessed through this instruction.
#+END_SRC

***** /C/-instructions 
#+BEGIN_SRC 
Syntax:    dest=comp;jump
Binary:    111a cccc ccdd djjj
Comments:  The first bit (1) signifies a C-instruction. "a" represents whether the ALU should operate on data (D/A) or a pointer to other data (D/M). "c" represents an computation input to the ALU. "d" represents the register(s) which will receive the ALU's output. "j" represents the jump conditions and effects the location in instruction memory which will be fetched next.
#+END_SRC

**** 6.2.3 - Symbols 
Hack assembly commands can refer to memory addresses or to either constants or symbols. Symbols in assembly programs come from three sources:

***** Predefined symbols
Any Hack assembly program can use the following predefined symbols:

|--------+-----------------------+-------------------|
| Label  | RAM address (decimal) | RAM address (hex) |
|--------+-----------------------+-------------------|
| SP     |                     0 |            0x0000 |
| LCL    |                     1 |            0x0001 |
| ARG    |                     2 |            0x0002 |
| THIS   |                     3 |            0x0003 |
| THAT   |                     4 |            0x0004 |
| R0-R15 |                  0-15 |          0x0000-f |
| SCREEN |                 16384 |            0x4000 |
| KBD    |                 24576 |            0x6000 |
|--------+-----------------------+-------------------|

***** Label symbols 
=(LOOP)= and such

***** Variable symbols 
yeah

*** 6.3 - Implementation 
=Assembler= is available as a shell script =Assembler.sh=. The Hack assembler reads a text file as input, in this chapter's case =Prog.asm=. It will then output a text file containing machine code, called =Prog.hack=. We call the assembler with the syntax =$ Assembler sourcefile.asm=.

The translation that takes place is one-to-one.

**** A note about API notation 
We propose an assembler implementation based on four modules: A /Parser/ module that parses the input, a /Code/ module that provides the binary codes of all of the assembly mnemonics, a /SymbolTable/ module that handles symbols, and a main program that drives the whole thing.

This assembler development is the first in a series of five software construction projects that build our hierarchy of translators (*assembler*, *virtual machine*, and *compiler*).

This book provides a language-agnostic API consisting of modules (C# =using= or =namespace=, Java =include= or =package=, C++ =include=, =using=, or =namespace=, JS =import= or =require=... etc.)

**** 6.3.1 - The Parser Module 
The main function of the parser is to break each assembly command into its underlying components (fields and symbols). The API is as follows:

***** Parser 
Encapsulates access to input code. Reads an assembly language command, parses it, and *provides convenient access to the command's components (fields and symbols). *In addition, *removes all whitespace and comments.*

#+BEGIN_SRC 
Routine:    Constructor/initializer
Arguments:  Input file/stream
Returns:    ---
Function:   Opens the input file/stream and gets ready to parse it.
#+END_SRC

****** Attempt at reverse-engineering
#+BEGIN_SRC c
#include <parser.h>

int main(int argc, int* argv) {
  if (sizeof(argv)/sizeof(int) > 2) {
    printf("Usage: Assembler <sourcefile.asm>"); 
  } 
  
  FILE* sourcefile = fopen(argv[1]);
  // parse file by-line
  // do all the other stuff
}
#+END_SRC

#+BEGIN_SRC 
Routine:    hasMoreCommands
Arguments:  ---
Returns:    Boolean
Function:   Are there more commands in the input?
#+END_SRC

#+BEGIN_SRC 
Routine:    advance
Arguments:  ---
Returns:    ---
Function:   Reads the next command from the input and makes it the current command. Should be called only if `hasMoreCommands()` is true. Initially there is no current command.
#+END_SRC

#+BEGIN_SRC 
Routine:    commandType
Arguments:  ---
Returns:    A_COMMAND, C_COMMAND, L_COMMAND
Function:   Returns the type of the current command:
  - A_COMMAND for @Xxx where Xxx is either a symbol or a decimal number.
  - C_COMMAND for dest=comp;jump
  - L_COMMAND (pseudo-command) for (Xxx), where Xxx is a symbol.
#+END_SRC

#+BEGIN_SRC
Routine:    symbol
Arguments:  ---
Returns:    string
Function:   Returns the symbol or decimal Xxx of the current command @Xxx or (Xxx). Should be called only when commandType() is A_COMMAND or L_COMMAND.
#+END_SRC

#+BEGIN_SRC
Routine:    dest
Arguments:  ---
Returns:    string
Function:   Returns the `dest` mnemonic in the current C-command (8 possibilities). Should be called only when commandType() is C_COMMAND.
#+END_SRC

#+BEGIN_SRC
Routine:    comp
Arguments:  ---
Returns:    string
Function:   Returns the `comp` mnemonic in the current C-command (8 possibilities).
#+END_SRC

#+BEGIN_SRC
Routine:    jump
Arguments:  ---
Returns:    string
Function:   Returns the `jump` mnemonic in the current C-command (8 possibilities).
#+END_SRC
 w/
**** 6.3.2 - The /Code/ Module 
***** Code
Translate Hack assembly language mnemonics into binary codes.

#+BEGIN_SRC
Routine:    dest
Arguments:  mnemonic (string)
Returns:    3 bits
Function:   Returns the binary code of the `dest` mnemonic.
#+END_SRC

#+BEGIN_SRC
Routine:    comp
Arguments:  mnemonic (string)
Returns:    7 bits
Function:   Returns the binary code of the `comp` mnemonic.
#+END_SRC

#+BEGIN_SRC
Routine:    jump
Arguments:  mnemonic (string)
Returns:    3 bits
Function:   Returns the binary code of the `jump` mnemonic.
#+END_SRC

**** 6.3.3 - Assembler for Programs with No Symbols 
At first, try building an assembler that doesn't pay attention to symbols and only translates instructions. This can be done with just the /Parser/ and /Code/ modules. Next, try extending the assembler in this state in order to handle symbols.

**** 6.3.4 - The /SymbolTable/ Module 
Since Hack instructions can contain symbols, the symbols must be resolved into actual addresses. We deal with this using a /symbol table/, designed to create and maintain correspondence between symbols and their meaning. A natural data structure for representing such a relationship is a hash table. Its methods are typical of the data structure.

**** 6.3.5 - Assembler for Programs with Symbols 
Try to implement the assembler in two passes:

***** Initialization
Initialize the symbol table with all predefined symbols and their pre-allocated RAM addresses, according to section 6.2.3.

***** First pass 
Go through the entire assembly program, line by line, and build the symbol table without generating any code. Keep a running number recording the ROM address into which the current command will be eventually loaded. Each time a pseudocommand ( Xxx ) is encountered, add a new entry to the symbol table accordingly. *This pass results in entering all the program's labels along with their ROM addresses into the symbol table*. The program's variables are handled in the second pass.

***** Second pass 
Do the same thing with variables, only assign the symbols by RAM address rather than ROM location.

*** 6.4 - Perspective 
Assemblers for richer machine languages are more complex than this one, and usually feature more sophisticated symbol handling. For example, the assembler may allow programmers to explicitly associate symbols with particular data addresses. Also, many assemblers can use *macro commands*.

A /macro command/ is a sequence of machine instructions that has a name. For example, say we named a macro command to be equal to ~D=M[Xxx]~; this could effectively replace two commands in our language: =@Xxx= and ~D=M~.

Also, stand-alone assemblers are rarely used in practice. Computers often just compile things into machine code. It is possible, however, in some languages, to include assembly code within higher-level programs.

*** 6.5 - Project 
- Objective :: Develop an assembler that translates programs written in Hack assembly language into the binary code that can be understood by the Hack hardware platform. The assembler must implement the translation specification described in section 6.2.
- Resources :: The only tool needed fo rthis project is the programming language in which you will implement the assembler. The book also provides an assembler to check our work against.
- Contract :: A =Prog.asm= file loaded into the assembler will output a =Prog.hack= file. This output matches the one given by the book.

There's test programs and stuff just go do it



