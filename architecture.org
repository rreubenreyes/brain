* THE ELEMENTS OF COMPUTING SYSTEMS - Noam Nisan and Shimon Schocken
*** Key Sections

[[1-world-below][- The world below as we know it]]
[[1-hdl][- HDL]]
[[nand-project-01][- Project 01]]
[[nand-project-02][- Project 02]]
[[nand-project-03][- Project 03]]
** Introduction
This book teaches three things:

1. How computers work
2. How to break complex problems into manageable modules
3. How to develop large-scale hardware and software systems

We will be learning how to create a complete and working computer system, from the ground-up.

"/The only kind of learning which significantly influences behavior is self-discovered or self-appropriated--truth that has been assimilated in experience./"
*** The World Above
Consider this trivial code:

#+BEGIN_SRC C
int main (void) {
  printf("%s", "Hello world!");
  return 0;
}
#+END_SRC

This is written in C. Newcomers often see the =void= or =%s= and ask what they mean, because they tend to be a bit too low level to understand at first glance.

What if I told you this wasn't even scratching the surface? For the computer to understand C, it must /parse/ the text, /uncover/ the semantics, and /reexpress it/ into something that can be understood by a computer. This step is known as *compilation*. C compiles down to assembly code, which compiles down to machine code.

Also, consider that /machine language itself is also an abstraction/. It is a set of binary codes that was designed to work specifically with the machine that is running the code. That is, it must be realized with a certain /chipset/ that is built using a specific system architecture. These chipset devices contain registers, memory units, ALU, and so on.

Going even deeper, realize that each of these devices is functionally held together by /logic gates/: Specific combinations of transistors that deterministically produce the same logical output if given the same logical input.

The nuances of any computer program, starting from the first transistor and leading up to the UX, start from the very bottom--the first transistor.

An intimate understanding of the world below is one of the things that separates naive programmers from sophisticated developers--people who can create complex /technologies/, not just /applications/ (of technologies that already exist).
*** Abstractions
It is through building abstractions from the bottom up that we free up the mental capacity to actually go so far up.

We built the NAND gate, and we abstracted it away from our thoughts so that we could focus on other thing. This led to AND, which leads to OR, which leads to XOR, which leads to the adder... and so on. A good abstraction focuses only on "What is this thing doing?" rather than "How does it do it?".
*** The World Below
<<1-world-below>>
As we dive into the lands below, we'll find out more about the following...
**** High-Level Language Land
**** The Road Down to Hardware Land
**** Hardware Land
** Chapter 1: Boolean Logic
Every digital device is based on a set of chips designed to store and process information. They share the same common hardware: *Boolean logic gates*.
*** 1.1 - Background
This chapter focuses on the construction of logic gates. To do this, we'll need to know some Boolean algebra!
**** 1.1.1 - Boolean Algebra
There are two rules in Boolean algebra: Yes and no, /1 and 0/.
***** Truth tables
The most common and simplest way to specify a Boolean function is to write a truth table, which graphically represents a given Boolean function's output for given input. They can also be represented as mathematical functions. See [[fig-1.1][Figure 1.1]].

+--------+--------+--------+--------+
|x       |y       |z       |f(x,y,z)|
+--------+--------+--------+--------+
|0       |0       |0       |0       |
+--------+--------+--------+--------+
|0       |0       |1       |0       |
+--------+--------+--------+--------+
|0       |1       |0       |1       |
+--------+--------+--------+--------+
|0       |0       |1       |0       |
+--------+--------+--------+--------+
|1       |0       |0       |1       |
+--------+--------+--------+--------+
|1       |0       |1       |0       |
+--------+--------+--------+--------+
|1       |1       |0       |1       |
+--------+--------+--------+--------+
|1       |1       |1       |0       |
+--------+--------+--------+--------+
/Figure 1.1: Truth table representation of a Boolean function =f(x, y, z) = (x + y) * z'=. <<fig-1.1>>/
***** Canonical representation
Also called /minterm/ and /maxterm/:

- The /minterm/ is gathered by taking a truth table and Adding together literals whose combinations produce a function output of =1=,then Or-ing those terms together.
- The /maxterm/ is gathered by taking a truth table and doing the same thing, but in reverse order.

Doing either of these results in an expression that is equivalent to the logic expressed by the entire truth table. Using the canonical representation is a way to formulate a simple expression.

This also teaches us that *all Boolean functions can be built with =And=, =Or=, and =Not=.*
**** 1.1.2 - Gate Logic
A /gate/ is a physical device that implements a Boolean function. Physically, a gate works by connecting I/O to I/O pins. The structure of the gate determines what the input/output of each pin should be to achieve a particular result. Gates are implemented today using /transistors/.

We begin our process of abstraction with gates.
***** Primitive and composite gates
A /composite gate/ is simply an implementation of a (usually more complex than normal) logical function through the use of two or more gates. For example, the three-input =And= is implemented by =And(And(a, b), c)=.

A gate /interface/ refers to dealing mainly with the gate's I/O, while gate /implementation/ deals with actually putting the circuit together using primitive gates. The only reason computer programmers really deal with gate implementation is to try to optimize low-level logic past what is currently possible in a given system. Meaning, the only requirement a computer programmer needs out of working with gates is the guarantee that all gates of the same type will produce the same results, with the same interface.
**** 1.1.3 - Actual hardware construction
While it is easy to chain together primitive gates to arrive at simpler composite gate designs, testing the logical function of these gates quickly becomes physically unviable if we were to be building these gates ourselves. This is why we use virtual tools like /HDL (Hardware Description Language)/ and /VHDL (Virtual HDL)/.
**** 1.1.4 - Hardware Description Language (HDL) <<1-hdl>>
<2019-01-15 Tue 11:50>
HDL/VHDL is a fancy way to imply that "we test our circuits in a simulation environment". HDL is the standard by which many gates are tested before fabrication, and is the first language abstraction we have run into so far.
***** Guts of a HDL program
There are a few parts to an HDL program:
****** Header
The /header/ section specifies the chip /interface/ (=CHIP=). It specifies the chip name and the names of all input and output pins.
****** Parts
The /parts/ (=PARTS=) section describes the names and topology of all the lower-level parts (other chips) from which this particular chip is constructed. Each part is represented by a /statement/ that specifies this part name, and crucially, the way it is connected to the other parts of the design.

Inter-part connections are described by creating and connecting /internal pins/ as needed. All =PARTS= connections are passed into gate interfaces as needed. See [[1-fig-1.6a][Figure 1.6a]] for an implementation of HDL to construct a XOR gate.

#+BEGIN_SRC
/* Xor.hdl */
CHIP Xor {
  IN a, b; /* these are external */
  OUT out; /* same */
  PARTS:
    Not(in=a, out=nota); /* using a new internal pin `nota` */
    Not(in=b, out=notb); /* the fact that `Not` has input pin `in` is an API specification */
    And(a=a, b=notb, out=w1);
    And(a=nota, b=b, out=w2);
    Or(a=w1, b=w2, out=out);
}
#+END_SRC
/Figure 1.6a: A =Xor= gate implemented in HDL./ <<1-fig-1.6a>>
****** Testing
HDL scripts are contained within file extension =.hdl=, while tests are contained within =.tst=. A test script simply assigns binary inputs to the chip interface and produces the logical output file to a =.out= file, as a truth table. The syntax is as follows ([[1-fig-1.6b][Figure 1.6b]]).

#+BEGIN_SRC
load Xor.hdl,
output-list a, b, out;
set a 0, set b 0;
eval, output;
set a 0, set b 1;
eval, output;
set a 1, set b 0;
eval, output;
set a 1, set b 1;
#+END_SRC
/Figure 1.6b: A =Xor= gate test, =Xor.tst=./ <<1-fig-1.6b>>
**** 1.1.5 -  Hardware Simulation
Since HDL is a hardware construction /language/, the process of writing and debugging HDL programs is pretty much the same as in software development. If we were using a compiled language like C, we would send our raw code to a compiler to be translated into assembly. Instead, however, we use a /hardware simulator/.

A hardware simulator is also a computer program... it's really just a HDL compiler, but the purpose of HDL is very specific, hence the name of the compiler.
*** 1.2 - Specification
Now we will specify a typical set of gates, each designed to carry out a common Boolean operation. We will be following these gates all the way to the design of a modern computer!
**** 1.2.1 - Nand
The truth table specification is as follows:
+-----+-----+----------+
|a    |b    |Nand(a, b)|
+-----+-----+----------+
|0    |0    |1         |
|0    |1    |1         |
|1    |0    |1         |
|1    |1    |0         |
+-----+-----+----------+

The API specification is as follows:
#+BEGIN_SRC
Chip name: Nand
Inputs:    a, b
Outputs:   out
Function:  If a=b=1 then out=0 else out=1
Comment:   This gate is considered primitive and thus there is no need to implement it.
#+END_SRC
**** 1.2.2 - Basic Logic Gates
Here is the API specification for other basic logic gates.
***** Not
#+BEGIN_SRC
Chip name: Not
Inputs:    in
Outputs:   out
Function:  If in=0 then out=1 else out=0
#+END_SRC
***** And
#+BEGIN_SRC
Chip name: And
Inputs:    a, b
Outputs:   out
Function:  If a=b=1 then out=1 else out=0
#+END_SRC
***** Or
#+BEGIN_SRC
Chip name: Or
Inputs:    a, b
Outputs:   out
Function:  If a=1 or b=1 then out=1 else out=0
#+END_SRC
***** Multiplexor
#+BEGIN_SRC
Chip name: Mux
Inputs:    a, b, sel
Outputs:   out
Function:  If sel=0 then out=a else out=b
#+END_SRC

A multiplexor is a three-input gate that uses one of the inputs as a /selection bit/, and picks either =a= or =b= as its output depending on that selection bit. (=a= and =b= are usually the result of other input functions!)
***** Demultiplexor
#+BEGIN_SRC
Chip name: DMux
Inputs:    in, sel
Outputs:   a, b
Function:  If sel=0 then {a=in, b=0} else {a=0, b=in}
#+END_SRC
A demultiplexor is similar in that it takes in a single input plus a selection bit, then produces two outputs. One of the outputs (=a= or =b=) is then assigned the value of =in= depending on the value of =sel=.
**** 1.2.3 - Multi-Bit Versions of Basic Gates
Today, computer hardware is typically designed to operate on multi-bit arrays, not just single bits. These are called /buses/. A 32-bit bus, for example, simply operates on 32 bits at once, taking in 32 inputs from an input bus, and outputting another 32 bits. The buses do not incorporate multiple gates /in series/, but rather /in parallel/, so that outputs are all individual.
**** 1.2.4 - Multi-Way Versions of Basic Gates
An /n-way/ gate, on the other hand, /does/ wire primitive gates in series. An /8-way =Or= gate/, for example, has eight input pins, =in[8]=, and produces a single output if any of those input pints are set to =1=.
***** The M-Way/N-Bit Multiplexor
Multiplexors used multi-bit multi-way are essential in constructing computer platforms. Let's break it down:

A *16-bit multiplexor* consists of an input =in[16]= plus selection bit =sel=, and an output =out[16]=:
#+BEGIN_SRC
Chip name: Mux4
Inputs:    in[16], sel
Outputs:   out[16]
Function:  If sel=0 then for i=0...15 out[i]=a[i] ... else out[i]=b[i]
#+END_SRC

A *4-way multiplexor* consists of an input =in[4]= plus two selection bits, corresponding to the number of possible input permutations, and a single output:
#+BEGIN_SRC
Chip name: Mux4Way
Inputs:    in[4], sel0, sel1
Outputs:   out
Function:  If Nand(sel0, sel1) then out=in[0], if sel0, Not(sel1) then out=in[1] ... etc.
#+END_SRC

A *16-bit, 4-way multiplexor* consists of four 16-bit inputs =a[16], b[16], c[16], d[16]= plus two selection bits and an output =out[16]=:
#+BEGIN_SRC
Chip name: Mux4Way16
Inputs:    a[16], b[16], c[16], d[16], sel[2]
Outputs:   out[16]
Function:  If sel=00 then out=a, if sel=01 then out=b, ... etc.
#+END_SRC
Note what is special about this chip: *It takes 4 possible 16-bit inputs, and turns it into one 16-bit output.* The usefulness of a selection bit is now much more obvious!
*** 1.3 - Implementation
Primitive gates are our elementary building blocks. In particular, we will build an entire computing system off of just one primitive gate: =Nand=. The following primitive gates can be build using just Nand: =Nand -> Not -> And -> Or/Xor -> Mux/DMux -> Multi-bit primitives -> Multi-bit Mux -> Multi-way=
*** 1.4 & 1.5 - Perspective and Project
We use =Nand= as our single primitive as a means of teaching, though it is not the only way to build computer systems from the ground up. We can study /digital design/ or /logic design/ for more in-depth knowledge.
**** DONE Project 01 <<nand-project-01>>
([[file:~/git-repos/nand2tetris/01][completed project files)]]

- OBJECTIVE :: Implement all the logic gates presented in the chapter. The only building blocks that you can use are primitive Nand gates and the composite gates that you will gradually build on top of them.
- RESOURCES :: Use the hardware simulator provided by /nand2tetris/. All chips should be implemented in HDL, with accompanying tests. Some HDL files or test files are missing, and it is our job to figure out how to re-implement those.
- CONTRACT :: When loaded into the hardware simulator, our chip design should produce the outputs listed in the supplied =.cmp= file.
- STEPS ::
- Read Appendix A1 - A6.
- Go through the /hardware simulator tutorial/ parts I, II, and III.
- Build and simulate all the chips specified in =projects/01=.

<2019-01-16 Wed>
***** DONE Project log
CLOSED: [2019-01-16 Wed 08:52]
****** DONE And
CLOSED: [2019-01-15 Tue 15:34]
******* =builtIn= directory must be relative to a script's root directory or included in the script folder itself
****** DONE Or
CLOSED: [2019-01-15 Tue 15:31]
****** DONE Xor
CLOSED: [2019-01-15 Tue 16:25]
******* scratch
#+BEGIN_SRC
MINTERM a'b + ab' = f(a, b)
#+END_SRC
****** DONE Mux
CLOSED: [2019-01-15 Tue 16:25]
******* scratch
#+BEGIN_SRC
ALIAS sel = s
MINTERM: f(a, b, s) = a'bs + ab's' + abs' + abs
DISTRIBUTIVE:
  f(a, b, s) = a'bs + a(b's' + bs' + bs)
             = a'bs + a(b(s + s') + b's')
             = a'bs + a(b + b's')
             = a'bs + ab + ab's'
             = as' + bs
#+END_SRC
****** DONE DMux
CLOSED: [2019-01-15 Tue 20:23]
******* scratch
#+BEGIN_SRC
IN: in, sel
OUT: a, b
ALIAS x = in
ALIAS y = sel
MINTERMS(a): xy'
MINTERMS(b): xy
#+END_SRC

*minterms/maxterms can be isolated by output and then superimposed*
****** DONE And16
CLOSED: [2019-01-15 Tue 20:35]
****** DONE Or16
CLOSED: [2019-01-15 Tue 20:37]
****** DONE Mux16
CLOSED: [2019-01-15 Tue 20:40]
****** DONE Mux4Way16
CLOSED: [2019-01-16 Wed 08:30]
******* scratch
*logic design involves a lot of looking for bitwise patterns and applying gradual abstractions*
****** DONE Mux8Way16
CLOSED: [2019-01-16 Wed 08:36]
****** DONE DMux4Way
CLOSED: [2019-01-16 Wed 08:46]
****** DONE DMux8Way
CLOSED: [2019-01-16 Wed 08:52]
*** Appendix A (A1 - A6): Hardware Description Language (HDL)
**** A.1 - HDL Program Example
[[a1-fig-a.1][Figure A.1]] specifies a chip that accepts two three-bit numbers and outputs whether they are equal or not.

#+BEGIN_SRC
Chip name: Eq3
Inputs:    a[3], b[3]
Outputs:   out
Function:  If a=b then out=1 else 0

CHIP Eq3 {
  IN a[3], b[3];
  OUT out;
  PARTS:
    Xor(a=a[0], b=b[0], out=c0);
    Xor(a=a[1], b=b[1], out=c1);
    Xor(a=a[2], b=b[2], out=c2);
    Or(a=c0, b=c1, out=c01); /* check if first bit and second bit are equal */
    Or(a=c01, b=c2, out=neq); /* check if first, second, third bit are equal */
    Not(in=neq, out=out);
}
#+END_SRC
/Figure A.1. <<a1-fig-a.1>>/
***** HDL API
Ths HDL bundled with the book contains a standard library =builtIn=. Parts can be referenced from this library by using =BUILTIN [built-in component]=.
** Chapter 2: Boolean Arithmetic
[2019-01-16 Wed 18:25]

In this chapter we build gate logic designs that represent numbers /and perform arithmetic operations on them/. We will go from all the basic gates we did in chapter 1, all the way to an *Arithmetic Logic Unit (ALU)* at the end of the chapter! In the following chapters we will build up to a fully functioning CPU.
*** Coursera Unit 2.1: Binary Numbers
In previous chapters, we've worked only with turning boolean values into more boolean values. However, binary can be used to represent "normal" arithmetic just as in decimal or other number systems.
*** Coursera Unit 2.2: Binary Addition
(this is fundamental and for the most part i know all of this)
*** Coursera Unit 2.3: Negative Numbers
We know that an =n=-digit /unsigned/ binary number can represent =2^n= values. For example, a 3-bit bus can have 8 (=2^3=) possible values.

That happens to be the same for /signed/ binary numbers. All we have to do is look at the leftmost bit; if it's =1=, then the number is negative, else it's positive.
**** 2's complement - Calculating signed binary numbers
***** Negation
An =n=-bit negative number =-x= can be thought of as =2^n - x=.
***** Bitwise negation
To negate a number in binary, we use *2's complement*. This is done by taking the /1's complement/ (flip all the bits) and adding 1:

#+BEGIN_SRC
3 = 0b0011
-3 = ^0b0011
   = 0b1100 + 1
   = 0b1101
#+END_SRC
*** Coursera Unit 2.4: ALU
The ALU is the brain-child of John Von Neumann. In Von Neumann Architecture,

=[INPUT] -> [MEMORY] <-> [CPU: {ALU | CONTROL}] -> [OUTPUT]=

the ALU exists within the CPU and is a central part in communicating with a computer's memory and output.
**** ALU specification
#+BEGIN_SRC
Chip name: ALU
Inputs:    in1, in2, f (where f is one of a family of pre-defined logical functions)
Outputs:   f(in1, in2)
Function:  Dependent on f
#+END_SRC
**** The Hack ALU
We will be building a Hack Computer in this course, so let's build a Hack ALU!

Hack ALU specification:
#+BEGIN_SRC
Chip name: HackALU
Inputs:    x[16], y[16], zx, nx, zy, ny, f, no
Outputs:   out[16], zr, ng
Function:  Many pre-defined functions defined by control bits
#+END_SRC
:w

The six control bits =zx, nx, zy, ny, f, no= define a /directive/ for the Hack ALU. It will compute many functions based on their input; for example, =000111= tells the ALU to compute =y - x=.
**** Hack ALU control bits
- =zx= - =if zx then x\=0=
- =nx= - =if nx then x\=!x=
- =zy= - =if zy then y\=0=
- =ny= - =if ny then y\=!y=
- =f= - =if f then out\=x+y else out\=x&y=
- =no= - ~if no then out\=!out~

The six control bits combine a /superposition/ of each of the functions specified by each bit. That is: =F(x, y) = z(x) + n(x) + z(y) + n(y) + f(x, y)=. This means that *the Hack ALU can compute any of 64 different function combinations.*
***** Example: Compute !x
- IN :: ~x=0b1100~ ~y=1011~
- CONTROL BITS :: =001101=

#+BEGIN_SRC
n(x) = 0: x = 1100
z(x) = 0: x = 1100
n(y) = 1: y = 0000
z(y) = 1: y = 1111
f(x, y) = 0:
  x & y = 1100
no = 1: out = 0011 === !x
#+END_SRC
***** Caveat
The ALU is just an implementation /of an abstraction/ of the previous basic logic gates we've created before. There is nothing too magical about it, other than the fact that somebody decided to combine a bunch of (very useful) bitwise functions into one unit.
**** Output control bits
- =zr= - ~if out=0 then zr=1 else 0~
- =ng= - ~if out<0 then ng=1 else 0~
***** Caveat
This becomes important a bit later down the line when we build a CPU!
**** Perspective
The Hack ALU is ideal for teaching purposes because of its simplicity, elegance, and ease of implementation. The bitwise functions it covers are fairly straightforward; they are visibly based off of early abstractions.

As we said before, the ALU is just putting a bunch of our previous chips into one chip!
*** Project 02 <<nand-project-02>>
- GIVEN :: All the chips built in Project 01!
- OBJECTIVE :: Build the a =HalfAdder=, =FullAdder=, =Add16=. =Inc16=, and =ALU=.
  - Note that these chips are all computational chips, going from simple to more complex.
  - Going from our previous example, we can see the trends we've been emphasizing regarding computational chips being simple extensions of basic logic gates. For example:
    - A =HalfAdder= has two outputs, =sum= and =carry=. Its truth table indicates that it can be implemented with just two basic chips: ~sum(a, b) = Xor(a, b)~ and ~carry(a, b) = And(a, b)~.
**** scratch
***** DONE HalfAdder
CLOSED: [2019-01-17 Thu 09:28]
+-----+-----+-----+-----+
|a    |b    |sum  |carry|
+-----+-----+-----+-----+
|0    |0    |0    |0    |
|0    |1    |1    |0    |
|1    |0    |1    |0    |
|1    |1    |0    |1    |
+-----+-----+-----+-----+
#+BEGIN_SRC
MINTERMS(sum):   a'b + ab'
MINTERMS(carry): ab
#+END_SRC
***** DONE FullAdder
CLOSED: [2019-01-17 Thu 09:39]
+-----+-----+-----+-----+-----+
|a    |b    |c    |sum  |carry|
+-----+-----+-----+-----+-----+
|0    |0    |0    |0    |0    |
|0    |0    |1    |1    |0    |
|0    |1    |0    |1    |0    |
|0    |1    |1    |0    |1    |
|1    |0    |0    |1    |0    |
|1    |0    |1    |0    |1    |
|1    |1    |0    |0    |1    |
|1    |1    |1    |1    |1    |
+-----+-----+-----+-----+-----+
#+BEGIN_SRC
MINTERMS(sum):   a'b'c + a'bc' + ab'c' + abc
  = a'(b'c + bc') + a(b'c' + bc)

MINTERMS(carry): a'bc + ab'c + abc' + abc
  = a(b'c + bc' + bc) + a'bc
  = a(b'c + b) + a'bc
  = ab'c + ab + a'bc
  = ab + ac + bc
#+END_SRC
***** DONE Add16 (16-bit adder)
CLOSED: [2019-01-17 Thu 09:50]
chain together a bunch of full adders
***** DONE Inc16 (16-bit incrementor)
CLOSED: [2019-01-17 Thu 09:52]
***** DONE ALU
CLOSED: [2019-01-17 Thu 10:16]
****** Chapter 2.3 - Implementation
This ALU can be reduced to implementing simple Boolean operations based on the ALU's six control bits. To start:
******* DONE implement a 16-bit input according to =nx= and =zx=
CLOSED: [2019-01-17 Thu 10:08]
******* DONE implement a 16-bit input according to =ny= and =zy=
CLOSED: [2019-01-17 Thu 10:08]
******* DONE pipe the results of =nxzx= and =nyzy= into the remaining input pins
CLOSED: [2019-01-17 Thu 10:16]
*** Perspective
*In any given computer, the overall functionality of the hardware/software platform is delivered jointly by the ALU and OS that runs on top of it.* When designing a new computer system, the decisions made when designing an ALU are a constant cost/performance tradoff.

*The general rule is that hardware implementations of arithmetic/logic are more expensive, but higher performing. Software abstractions are the opposite.*

The Hack ALU built in this course is designed to build off of previous chapters, and won't necessarily reflect most common ALU design decisions.
** Chapter 3: Sequential Logic
Chapters 1 and 2 covered /combinational chips/, in that the functions they compute depend solely on their input values. They are great for fast, high-performing requirements, but are unviable if we need our chips to maintain /state/.

/Sequential chips/ are what memory devices are made of; memory chips by definition are stateful. This chapter introduces the concepts of *synchronization*, *clocking*, and *feedback loops*, all of which are used to manipulate bits to be stateful. The name "sequential" comes from the fact that a sequential chip's output depends also on what was input in the /sequence/ before the current one.

We will start by building a very low-level sequential gate called a *flip-flop*. Flip-flops can be thought of as the building blocks for most sequential chips.
*** 3.1 - Background
Sequential logic chips are based on memory. Memory is based on time; we can remember /now/ something that happened /before/. *To implement memory, we must "implement" time.*
**** The Clock
In most computers, the passage of time is represented by a master clock which constantly alternates between two signal states. The output of this clock is fed to every sequential chip throughout an entire computer platform. We call the phases of this clock /low-high/, /0-1/, /tick-tock/, etc. Where ~out(0) = tick~ and ~out(1) = tock~.
**** Flip-Flops
Also called *DFFs* (/data flip-flops/). A DFF's interface consists of a single-bit data input and a single-bit data output, along with a clock input that is continuously changing. Taken together, the =data= input and =clock= input allow the DFF to implement some function ~out(t) = in(t-1)~. *A DFF simply outputs the input from the previous time cycle.*

DFFs are what we use as an elementary /stateful unit/. A very common example is a /register/.
**** Registers
A *register* is a storage device that can "remember" a value over time, implementing the storage behavior ~out(t) = out(t-1)~.

This means that *a register can be implemented from DFF simply by feeding the output of the DFF back into the input*. In order for a register to be able to handle both ~out = in(t-1)~ (write functionality) and ~out = out(t-1)~ (read functionality), we must use a conditional directive. Fortunately we can do this with a multiplexor, whose sole purpose is to select read/write based on a =load= variable.

Like in many of our low-level abstractions, once we've figured this out, we can make registers of any size, or /width/. The multi-bit contents of a multi-bit register are sometimes called /words/.
**** Memories
Once we have the ability to represent words, we can proceed to build /memory banks/ of arbitrary length. In order to build *RAM*, for example, we can simply stack together a whole bunch of registers.
***** Random-access memory (RAM)
The distinguishing property of RAM comes from the "random" part. It should be able to access randomly chosen words; *any word in the memory, /irrespective of its physical location/, should have the same access speed as any other word*. This requirement can be satisfied as follows:

1. We assign each word in the /n/-register RAM a unique /address/.
2. Alongside the /n/-register RAM, we build a gate logic design that, given an address =j=, can select the individual register with that same address.
****** RAM architecture
A classical RAM device accepts three inputs: *data*, *address*, and *load bit*. The purpose of each of these pins:

- The /address/ specifies which RAM register should be accessed in the current time step.
- The /load bit/ specifies whether to *read* (i.e. access ~out = out(t - 1)~) or *write* (i.e. access ~out = in(t - 1)~).
  - In the case of a read operation, the RAM's output immediately emits the value of the selected register at =&j=.
  - In the case of a write operation, the register at =&j= saves the data provided by the data bit in the current time step.
- The /data/ input specifies what should be written to a memory address in the case of a write operation.

The basic design paramters of a RAM device are its data /width/ (register capacity/max. word size) and its /size/ (total number of words in memory). For reference, modrern computers typically utilize 32-bit- or 64-bit-wide RAMs whose sizes are up to billions of words.
**** Counters
A /counter/ is a sequential chip whose state is an integer number that increments every time unit. Its characteristic is ~out(t) = out(t - 1) + c~, where =c= is the amount by which to increment the count.

Implementation of a counter is simple; it requires only one register in series and positive feedback with an incrementor. The load bit of a counter is usually not utilized unless we need to manually write a value to the counter's memory, or otherwise alter it; any combinational chip can be used to affect the load bit of this counter.
**** Overview
All of the chips we've discussed so far are /sequential/. It turns out that all sequential chips employ DFF gates at some level of the abstraction.

Technically speaking, this is done by forming feedback loops in combination with a selection directive, typically a multiplexor.

*Combinational chips change their outputs with their inputs*, meaning they are zero-order with respect to time--~f(...in) = out(...in)~.

*Sequential chips change their outputs with their inputs /and/ with respect to time*--~f(t, ...in) = out(t, ...in)~. The term "sequential" also implies that they may only change w.r.t time, at most, every one clock cycle.
***** Caveat
Sequential chips like this are modeled /discretely/ (as in discrete math). If measured and modeled in continuous time, their outputs would actually be incredibly unstable, thus we choose to implement chips which are deterministic to exactly one clock cycle.

The advantage of this is that we get to model /every/ part of the computer architecture in a discrete time model, with the same deterministic properties applying for every part of our system. This proves crucial in later tasks like scheduling, context, and parallel computation (not threading!).

Low-level "race conditions" like in inputting data to an ALU (combinational) might pose problems if we didn't use sequential chips in some form or another. However, because a computer architecture is absolutely dependent on sequential devices, we don't have to care about these race conditions. All we need to do is design the clock cycle to be deterministic, in that *a clock cycle is slightly longer than the time it takes for a bit to travel the longest distance from one chip to another*, and only dealing with changes in state at the top of every clock cycle
*** 3.2 - Specification
The chips specified in this section:

- Data-flip-flops (DFFs)
- Registers (based on DFFs)
- Memory banks (based on registers)
- Counter chips (also based on registers)
**** 3.2.1 - Data-Flip-Flops
A DFF has a single-bit input and output. Specification:
#+BEGIN_SRC
Chip name:     DFF
Inputs:        in
Outputs:       out
Function:      out(t)=in(t-1)
Comment:       This clocked gate has a built-in implementation.
#+END_SRC

*DFFs are like the "sequential version of =Nand= gates"*, in that many sequential chips are really just a bunch of DFFs put together.

***** Fixed-time updating
At the top of each clock cycle, all DFFs in a computer system commit to their inputs during the previous time step. At all other times, the DFFs are "latched", meaning that any changes in their inputs don't immediately affect their outputs (until the next clock cycle).
**** 3.2.2 - Registers
A single-bit register, or /binary cell/, is designed to store a single bit of information. The chip interface consists of an data pin, load pin, and output pin. Specification:
#+BEGIN_SRC
Chip name:     Register
Inputs:        data, load
Outputs:       out
Function:      if load(t-1) out(t)=in(t-1) else out(t)=out(t-1)
#+END_SRC
***** Multi-bit registers
The implementation is nearly identical.
#+BEGIN_SRC
Chip name:     Register
Inputs:        data[16], load
Outputs:       out[16]
Function:      if load(t-1) out(t)=in(t-1) else out(t)=out(t-1)
#+END_SRC
**** 3.2.3 - Memory
A direct-access memory unit (i.e. RAM) is an array of =n= =w=-bit registers equipped with direct access circuitry (each of =n= cells is given an address and can hold a word of size =w=).

The RAM we will be building will be 16-bits wide, but will have varying sizes: =RAM8=, =RAM64=, =RAM512=, =RAM4K=, and =RAM16K=. All these chips have the same API:
#+BEGIN_SRC
Chip name:     RAMn // n = size, k = number of required address bits
Inputs:        in[16], address[k], load
Outputs:       out[16]
Function:      if load(t-1) then RAM[address(t-1)](t)=in(t-1)
#+END_SRC

***** Read/write
****** Read operations 
To read the contents of register number =m=, we send =&m= as the address input. The RAM's direct-access logic well select that register and emit its stored value to the output. *This operation is combinational*.

****** Write operations
To write a value =d= to the register =m=, we send =&m= into the address input and set the load bit to =true=. Direct access logic will again select that register, then store a new value =d=. The next read operation that occurs will cause a referenced =uint_t m* = d=. *This operation is sequential*.


**** 3.2.4 - Counter 
Consider a counter chip designed to contain the address of the instruction that the computer should fetch and execute next (/this falls under scheduling(?)/). In most cases, the counter must increment itself by 1 in each clock cycle, causing the computer to fetch the next instruction in the program. In other cases, such as a =jump= instruction, we want to be able to arbitrarily set the counter to some time step =n=, then have it continue its default behavior by then incrementing to =n+1=, =n+2=, etc. If there is any non-sequential (aka we need to jump, not sequential as in discrete time) /The only way we can implement this behavior is with a "loadable" and "resettable" counter./

Thus, we choose to implement counters similar to registers. They have two additional input pins, =inc= and =reset=. =inc= will cause the counter to increment its count by 1 if set to =true=, while =reset= will reset the counter to =0= if set to =true=. The =load= pin now serves so that we can affect the output with a multiplexed input fed to =in.=
#+BEGIN_SRC
Chip name:     PC // 16-bit counter
Inputs:        in[16], inc, load, reset
Outputs:       out[16]
Function:      if reset(t-1) then out(t)=0 else if load(t-1) then out(t)=in(t-1) else if inc(t-1) then out(t)=out(t-1)+1 else out(t)=out(t-1) 
#+END_SRC
*** 3.3 - Implementation 
**** Flip-Flop 
DFF gates can be implemented from lower-level logic gates. However, in this book we treat DFFs as primitive gates.

**** Register
Basically DFFs with positive feedback and controlled by a multiplexer.

**** Memory 
Combine =n= =w=-wide registers to make a memory bus of size =n=. We must provide this memory with a direct access system in order to read/write from any address in memory; this is done via an =address= pin. The =load= pin controls read/write; /read/ operations are combinational and take effect immediately upon access, while /write/ operations are sequential and take effect at the top of the next time step. The length of our input should be sufficient to access all =n= registers in memory; that is, if =n = 2^x=, then =input= should be =x=-bits long.

**** Counters 
A =w=-bit counter consists of a regular =w=-bit register plus combinational logic. The combinational logic can:

1. Compute the counting function (incrementor)
2. Put the counter in the right operating mode (=load=, =reset=, =inc=)

*** 3.4 - Perspective 
In this chapter, we considered the flip-flop to be the most primitive building block of all computer memory systems.

The usual approach in other books is to approach flip-flops as non-primitive, first starting from =Nand= gates as we have before. This requires some knowledge of controlling clock cycles and understanding of the effect of feedback loops on combinatorial circuits--in order to get to the point quickly, we just jump ahead to a stable flip-flop as our base.

Also, memory devices of modern computers /are not always constructed from standard flip-flops/. Instead, modern memory chips are usually carefully optimized and exploit the physical properties of the storage technology being used.

Other than these low-level details, everything that is considered an abstraction over flip-flops still remains standard today.

*** 3.5 - Project 03 
<<nand-project-03>>
[2019-01-18 Fri]
- GIVEN :: Hardware simulator, everything from this chapter and previous chapters.
- OBJECTIVE :: Build all the chips in this chapter. The only building blocks we can use are primitive DFF gates, chips that we will build on top of them ourselves, and chips described in previous chapters.

**** scratch 

***** DONE Bit (1-bit register) 
- State "DONE"       from "TODO"       [2019-01-18 Fri 11:06]
***** DONE Register (n-bit register)
- State "DONE"       from "TODO"       [2019-01-18 Fri 11:10]
***** DONE RAM8
- State "DONE"       from "TODO"       [2019-01-18 Fri 11:25]
***** DONE RAM64
- State "DONE"       from "TODO"       [2019-01-18 Fri 11:38]
***** DONE PC
- State "DONE"       from "TODO"       [2019-01-18 Fri 12:02]
conditions in low-level code often imply hierarchy

hierarchy in HDL starts from the lowest conditional clause and travels up
***** DONE RAM512
- State "DONE"       from "TODO"       [2019-01-18 Fri 12:10]
***** DONE RAM4K
- State "DONE"       from "TODO"       [2019-01-18 Fri 12:20]
***** DONE RAM16K

- State "DONE"       from "TODO"       [2019-01-18 Fri 12:20]
*** Appendix A (A7) - Sequential Chips 
**** A.7.1 - The Clock 
The simulator models the progression of time by supporting two operations called /tick/ and /tock/. They simulate a series of /time units/. Each /tick/ ends the first phase of a time unit and starts the second phase, while /tock/ ends the second phase of the current time unit and starts the first phase of the first.

During all /ticks/, the inputs of each sequential chip in the architecture are read and affect the chip's internal state.

During all /tocks/, the outputs of the chip are set to new values. The values of the output pins, regardless of a read/write operation, are deterministic to the end of each /tock/.

**** A.7.2 - Clocked Chips and Pins 
We can specify whether a pin should be clocked or not by =CLOCKED pin=. A =CLOCKED= pin will behave sequentially.

***** Caveat 
Any high-order pin =P= may have some lower-level pin implementation =Q=, that is =P= is an abstraction over =Q=. /if =Q= or any other child of =P= is clocked, then =P= is also clocked./
** Chapter 4: Machine Language 
A computer can be described /constructively/, by layout out its hardware platform and explaining how it's built from low-level chips.

It can also be described /abstractly/, by specifying its higher-level machine language capabilities. This is where the fun part starts. By focusing on low-level machine language code, we can understand how to manipulate the computer to run /any/ machine language program and complete our general-purpose build.

*Machine language* is the first line in the computer enterprise where hardware and software meet. It is a formalism designed to code low-level programs as a series of machine instructions. Because it is the first instance where abstract code is transformed into actual physical activity, *machine language can be thought of as both a programming tool and an integral part of computer hardware*.
*** 4.1 - Background 
**** 4.1.1 - Machines 
A /machine language/ can be viewed as a formalism designed to manipulate /memory/ using a /processor/ and a set of /registers/.

***** Memory  
The term /memory/ refers loosely to the collection of hardware devices that store data and instructions in a computer.

From a programmer's standpoint, all memories are identical. All have some word/location /width/ and an /address/. We're probably used to accessing memory in this way via =Memory[address]=.

***** Processor
The processor is normally called the /central processing unit (CPU)/. We have implemented the CPU in the past by designing an ALU and its control outputs. CPUs are capable of a fixed set of elementary operations, namely those defined by the ALU.

The difference between the ALU and the CPU is that the CPU gets its inputs either from memory or from user input, and can also write to memory or some other output. Thus, it interfaces with those two parts in Von Neumann's architecture rather than being isolated.

***** Registers
Because memory access becomes gradually slower as it gets more nested (need to mux/demux several times the more nested a bus gets), we often want to keep some high-speed, "lower-order" local memory close to the processor. This concept should be familiar: Oftentimes it is implemented as a *stack* or *heap*, depending on the higher-level language implementation.

**** 5.1.2 - Languages 
A machine language program is a series of coded instructions.



